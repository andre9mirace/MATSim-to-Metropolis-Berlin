{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52001a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pyarrow\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import mpl_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from xopen import xopen\n",
    "from datetime import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d4fa4",
   "metadata": {},
   "source": [
    "# General Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b43493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "general_directory = '/Users/andre/Desktop/Cergy/'\n",
    "\n",
    "berlin_directory = 'MATSim/matsim-berlin/input/v6.4/'\n",
    "\n",
    "pt_10pct_dir = 'Python_Scripts/runs/pt_10pct/'\n",
    "\n",
    "# full paths\n",
    "NETWORK_PATH = (os.path.join(general_directory, berlin_directory, \"berlin-v6.4-network.xml.gz\"))\n",
    "VEHICLE_PATH = (os.path.join(general_directory, berlin_directory, \"berlin-v6.4-vehicleTypes.xml\"))\n",
    "MATSIM_TRIPS_PATH = (os.path.join(general_directory, pt_10pct_dir, \"matsim_trips/MATSim_trips.parquet\"))\n",
    "\n",
    "METRO_INPUT = (os.path.join(general_directory, pt_10pct_dir, \"metro_inputs/\"))\n",
    "METRO_OUTPUT = (os.path.join(general_directory, pt_10pct_dir, \"metro_outputs/\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74ddd9",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9044ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SHARE = 0.10\n",
    "\n",
    "# Parameters to use for the simulation.\n",
    "PARAMETERS ={\n",
    "    \"input_files\": {\n",
    "      \"agents\": (os.path.join(METRO_INPUT, \"agents.parquet\")) ,\n",
    "      \"alternatives\": (os.path.join(METRO_INPUT, \"alts.parquet\")),\n",
    "      \"trips\": (os.path.join(METRO_INPUT, \"trips.parquet\")),\n",
    "      \"edges\": (os.path.join(METRO_INPUT, \"edges.parquet\")),\n",
    "      \"vehicle_types\": (os.path.join(METRO_INPUT, \"vehicles.parquet\"))\n",
    "                },\n",
    "    \"output_directory\": METRO_OUTPUT,\n",
    "    \"period\": [0.0, 86400.0],\n",
    "    \"road_network\": {\n",
    "        \"recording_interval\": 950.0,\n",
    "        \"approximation_bound\": 1.0,\n",
    "        \"spillback\": True,\n",
    "        \"backward_wave_speed\": 15.0,\n",
    "        \"max_pending_duration\": 30.0,\n",
    "        \"constrain_inflow\": True,\n",
    "        \"algorithm_type\": \"Best\"\n",
    "    },\n",
    "    \"learning_model\": {\n",
    "      \"type\": \"Linear\"\n",
    "    },\n",
    "    \"init_iteration_counter\": 1,\n",
    "    \"max_iterations\": 350,\n",
    "    \"update_ratio\": 1.0,\n",
    "    \"random_seed\": 13081996,\n",
    "    \"nb_threads\": 16,\n",
    "    \"saving_format\": \"Parquet\",\n",
    "    \"only_compute_decisions\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd11af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_attributes(elem, my_dict):\n",
    "    for attrib in elem.attrib:\n",
    "        my_dict[attrib] = elem.attrib[attrib]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a00dc8",
   "metadata": {},
   "source": [
    "# Supply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd786d",
   "metadata": {},
   "source": [
    "## Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "742364e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_reader():\n",
    "    tree = ET.iterparse(xopen(VEHICLE_PATH, \"r\"), events=[\"start\", \"end\"])\n",
    "    vehicle_types = []\n",
    "    current_vehicle_type = {}\n",
    "    is_parsing_vehicle_type = False\n",
    "    for xml_event, elem in tree:\n",
    "        _, _, elem_tag = elem.tag.partition(\"}\")  # Removing xmlns tag from tag name\n",
    "        # VEHICLETYPES\n",
    "        if elem_tag == \"vehicleType\" and xml_event == \"start\":\n",
    "            parse_attributes(elem, current_vehicle_type)\n",
    "            is_parsing_vehicle_type = True\n",
    "        # ATTRIBUTES\n",
    "        elif elem_tag == \"attribute\" and xml_event == \"start\":\n",
    "            current_vehicle_type[elem.attrib[\"name\"]] = elem.text\n",
    "        # LENGTH / WIDTH\n",
    "        elif elem_tag in [\"length\", \"width\"] and xml_event == \"start\":\n",
    "            current_vehicle_type[elem_tag] = elem.attrib[\"meter\"]\n",
    "        # VEHICLETYPES\n",
    "        elif elem_tag == \"vehicleType\" and xml_event == \"end\":\n",
    "            vehicle_types.append(current_vehicle_type)\n",
    "            current_vehicle_type = {}\n",
    "            elem.clear()\n",
    "            is_parsing_vehicle_type = False\n",
    "        # EVERYTHING ELSE\n",
    "        elif is_parsing_vehicle_type and elem_tag not in [\"attribute\", \"length\", \"width\"]:\n",
    "            parse_attributes(elem, current_vehicle_type)\n",
    "    vehicle_types = pd.DataFrame.from_records(vehicle_types)\n",
    "    col_types = {\n",
    "        \"accessTimeInSecondsPerPerson\": float,\n",
    "        \"egressTimeInSecondsPerPerson\": float,\n",
    "        \"seats\": int,\n",
    "        \"standingRoomInPersons\": int,\n",
    "        \"length\": float,\n",
    "        \"width\": float,\n",
    "        \"pce\": float,\n",
    "        \"factor\": float,\n",
    "    }\n",
    "    for col, dtype in col_types.items():\n",
    "        if col in vehicle_types.columns:\n",
    "            try:\n",
    "                vehicle_types[col] = vehicle_types[col].astype(dtype)\n",
    "            except:\n",
    "                print(f\"dataframe types conversion failed for column {col}\")\n",
    "    return vehicle_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e794a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vehicles_df(vehicle_types):\n",
    "    vehicle_list = []\n",
    "\n",
    "    for idx, row in vehicle_types.iterrows():\n",
    "        if row[\"id\"] == \"ride\":\n",
    "            vehicle = {\n",
    "                \"vehicle_id\": idx,\n",
    "                \"vehicle_type\": row[\"id\"],\n",
    "                \"headway\": float(row[\"length\"]),\n",
    "                \"pce\": 0.0,\n",
    "                \"speed_function.type\": \"Base\",\n",
    "                \"speed_function.upper_bound\": None,\n",
    "                \"speed_function.coef\": None,\n",
    "            }\n",
    "        else:\n",
    "            vehicle = {\n",
    "                \"vehicle_id\": idx,\n",
    "                \"vehicle_type\": row[\"id\"],\n",
    "                \"headway\": float(row[\"length\"]),\n",
    "                \"pce\": float(row[\"pce\"]) / POPULATION_SHARE,\n",
    "                \"speed_function.type\": \"Base\",\n",
    "                \"speed_function.upper_bound\": None,\n",
    "                \"speed_function.coef\": None,\n",
    "            }\n",
    "        vehicle_list.append(vehicle)\n",
    "\n",
    "    vehicles = pl.DataFrame(vehicle_list)\n",
    "    vehicles = vehicles.filter(pl.col('vehicle_id')<5)\n",
    "    return vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d45a2",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e441e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_network():\n",
    "    tree = ET.iterparse(xopen(NETWORK_PATH, \"r\"), events=[\"start\", \"end\"])\n",
    "    links = []\n",
    "    \n",
    "    for xml_event, elem in tree:\n",
    "        if elem.tag == \"link\" and xml_event == \"start\":\n",
    "            atts = elem.attrib\n",
    "            atts[\"link_id\"] = atts[\"id\"].replace(\"#\", \"\")\n",
    "            atts[\"numeric_link_id\"] = int(atts[\"id\"].split(\"#\")[0])            \n",
    "            atts[\"from_node\"] = atts.pop(\"from\")\n",
    "            atts[\"to_node\"] = atts.pop(\"to\")\n",
    "\n",
    "            if \"cluster\" in atts[\"from_node\"]:\n",
    "                atts[\"from_node\"] = atts[\"from_node\"].replace(\"cluster_\", \"\").split(\"_\")[0]\n",
    "            if \"cluster\" in atts[\"to_node\"]:\n",
    "                atts[\"to_node\"] = atts[\"to_node\"].replace(\"cluster_\", \"\").split(\"_\")[0]\n",
    "\n",
    "            atts[\"length\"] = float(atts[\"length\"])\n",
    "            atts[\"freespeed\"] = float(atts[\"freespeed\"])\n",
    "            atts[\"capacity\"] = float(atts[\"capacity\"])\n",
    "            atts[\"permlanes\"] = float(atts[\"permlanes\"])\n",
    "            if \"volume\" in atts:\n",
    "                atts[\"volume\"] = float(atts[\"volume\"])\n",
    "            links.append(atts)\n",
    "\n",
    "        if elem.tag in [\"node\", \"link\"] and xml_event == \"end\":\n",
    "            elem.clear()\n",
    "\n",
    "    links = pd.DataFrame.from_records(links)\n",
    "    links = links.loc[links[\"modes\"].str.contains(\"car\")].copy()\n",
    "    links[\"link_id\"] = links[\"link_id\"].astype(int)\n",
    "    links[\"from_node\"] = links[\"from_node\"].astype(int)\n",
    "    links[\"to_node\"] = links[\"to_node\"].astype(int)\n",
    "\n",
    "    node_pair_counts = links[[\"from_node\", \"to_node\"]].value_counts()\n",
    "\n",
    "    new_rows = []\n",
    "\n",
    "    if node_pair_counts.max() > 2:\n",
    "        print(\"More than two parallel edges\")\n",
    "        print(f\"Maximum of {node_pair_counts.max()} parallel edges\")\n",
    "\n",
    "    # parallel edges\n",
    "    parallel_idx_gt2 = node_pair_counts.loc[node_pair_counts > 2].index\n",
    "    if len(parallel_idx_gt2):\n",
    "        print(f\"Handling {len(parallel_idx_gt2)} node pairs with more than 2 parallel edges...\")\n",
    "        next_node_id = max(links[\"from_node\"].max(), links[\"to_node\"].max()) + 1\n",
    "        next_link_id = links[\"link_id\"].max() + 1\n",
    "        for (source, target) in parallel_idx_gt2:\n",
    "            mask = (links[\"from_node\"] == source) & (links[\"to_node\"] == target)\n",
    "            idx = mask[mask].index\n",
    "            for i in range(1, len(idx)): \n",
    "                row = links.loc[idx[i]].copy()\n",
    "                row[\"length\"] = 0.0\n",
    "                row[\"from_node\"] = next_node_id\n",
    "                row[\"link_id\"] = next_link_id\n",
    "                new_rows.append(row)\n",
    "                links.loc[idx[i], \"to_node\"] = next_node_id\n",
    "                next_node_id += 1\n",
    "                next_link_id += 1\n",
    "\n",
    "    # 2 parallel edges\n",
    "    parallel_idx = node_pair_counts.loc[node_pair_counts == 2].index\n",
    "    if len(parallel_idx):\n",
    "        print(f\"Found {len(parallel_idx)} parallel edges\")\n",
    "        next_node_id = max(links[\"from_node\"].max(), links[\"to_node\"].max()) + 1\n",
    "        next_link_id = links[\"link_id\"].max() + 1\n",
    "        for (source, target) in parallel_idx:\n",
    "            mask = (links[\"from_node\"] == source) & (links[\"to_node\"] == target)\n",
    "            idx = mask[mask].index\n",
    "            if len(idx) < 2:\n",
    "                continue  \n",
    "            row = links.loc[idx[1]].copy()\n",
    "            row[\"length\"] = 0.0\n",
    "            row[\"from_node\"] = next_node_id\n",
    "            row[\"link_id\"] = next_link_id\n",
    "            new_rows.append(row)\n",
    "            links.loc[idx[1], \"to_node\"] = next_node_id\n",
    "            next_node_id += 1\n",
    "            next_link_id += 1\n",
    "\n",
    "    if new_rows:\n",
    "        links = pd.concat((links, pd.DataFrame(new_rows)), ignore_index=True)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba93785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edges_df(links):\n",
    "    edge_list = []\n",
    "\n",
    "    for i, (_, row) in enumerate(links.iterrows()):\n",
    "        edge = {\n",
    "            \"edge_id\": i+1,\n",
    "            \"MATSim_id\": row[\"id\"],\n",
    "            \"source\": int(row[\"from_node\"]),\n",
    "            \"target\": int(row[\"to_node\"]),\n",
    "            \"speed\": float(row[\"freespeed\"]),\n",
    "            \"length\": float(row[\"length\"]),\n",
    "            \"lanes\": float(row[\"permlanes\"]),\n",
    "            \"speed_density.type\": \"FreeFlow\",\n",
    "            \"speed_density.capacity\": None,\n",
    "            \"speed_density.min_density\": None,\n",
    "            \"speed_density.jam_density\": None,\n",
    "            \"speed_density.jam_speed\": None,\n",
    "            \"speed_density.beta\": None,\n",
    "            \"bottleneck_flow\": float(row[\"capacity\"])/ (row['permlanes']*3600.0),  # capacity per lane in vehicles per hour\n",
    "            \"constant_travel_time\": math.ceil(float(row[\"length\"]) / float(row[\"freespeed\"])) - float(row[\"length\"]) / float(row[\"freespeed\"]),\n",
    "            \"overtaking\": True\n",
    "        }\n",
    "        edge_list.append(edge)\n",
    "\n",
    "    edges = pl.DataFrame(edge_list)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd23d7b",
   "metadata": {},
   "source": [
    "# Create Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92bca222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MATSim vehicles\n",
      "dataframe types conversion failed for column seats\n",
      "dataframe types conversion failed for column standingRoomInPersons\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating MATSim vehicles\")\n",
    "vehicles = vehicle_reader()\n",
    "vehicles = make_vehicles_df(vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76344f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MATSim network\n",
      "More than two parallel edges\n",
      "Maximum of 3 parallel edges\n",
      "Handling 10 node pairs with more than 2 parallel edges...\n",
      "Found 1832 parallel edges\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating MATSim network\")\n",
    "links = read_network()\n",
    "edges = make_edges_df(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167511a",
   "metadata": {},
   "source": [
    "# Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca08a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trips(matsim_trips, edges, vehicles):\n",
    "    \n",
    "    # link (matsim) to edge (metro) dictionary\n",
    "    matsim_to_metro_links = dict(zip(edges[\"MATSim_id\"].cast(pl.Utf8), edges[\"edge_id\"]))\n",
    "    \n",
    "    metro_trips = matsim_trips\n",
    "    \n",
    "    # class.vehicle\n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .join(vehicles.select([\n",
    "            pl.col(\"vehicle_type\").alias(\"mode\"),\n",
    "            pl.col(\"vehicle_id\").alias(\"class.vehicle\")]),on=\"mode\", how=\"left\")\n",
    "        .with_columns([\n",
    "\n",
    "            # class.type\n",
    "            pl.when(pl.col(\"mode\").is_in(['truck', 'car', 'freight', 'ride']) #| pl.col(\"route\") is None\n",
    "                   )\n",
    "            .then(pl.lit(\"Road\"))\n",
    "            .otherwise(pl.lit(\"Virtual\"))\n",
    "            .alias(\"class.type\")])\n",
    "    )\n",
    "    \n",
    "    \n",
    "    metro_trips = (\n",
    "        \n",
    "    # class.type\n",
    "    metro_trips\n",
    "    .rename({'start_time':'dt_choice.departure_time'\n",
    "            })\n",
    "    .with_columns([\n",
    "                \n",
    "    # class.routes\n",
    "    pl.when(pl.col(\"class.type\") == \"Road\")\n",
    "      .then(pl.col(\"route\").str.split(\" \") # split route string\n",
    "            \n",
    "            # map in the dictionary\n",
    "            .map_elements(lambda link_list: None if link_list is None\n",
    "                          else [matsim_to_metro_links.get(link) for link in link_list[1:]],\n",
    "                          return_dtype=pl.List(pl.Int64))\n",
    "            .alias(\"class.route\"))\n",
    "      .otherwise(None),\n",
    "\n",
    "        \n",
    "    # class.travel_time\n",
    "    pl.when(pl.col(\"class.type\") == \"Road\")\n",
    "      .then(None)\n",
    "      .otherwise(pl.col(\"duration\"))\n",
    "    .alias(\"class.travel_time\")\n",
    "    ])\n",
    "    .drop(['person_id' , 'route', 'duration', 'end_time', 'mode'])\n",
    "    )\n",
    "    \n",
    "    # Join with edges for start_link's from and to nodes\n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .join(\n",
    "            edges.select([\n",
    "                pl.col(\"MATSim_id\").alias(\"start_link\"),\n",
    "                pl.col(\"target\").alias(\"class.origin\")]), # class.origin\n",
    "            on=\"start_link\",how=\"left\")\n",
    "        .drop(pl.col('start_link'))\n",
    "        .join(\n",
    "            edges.select([\n",
    "                pl.col(\"MATSim_id\").alias(\"end_link\"),\n",
    "                pl.col(\"target\").alias(\"class.destination\")]), # class.destination\n",
    "            on=\"end_link\", how=\"left\")\n",
    "        .drop(pl.col('end_link'))\n",
    "    )\n",
    "    \n",
    "    \n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .with_columns([\n",
    "            pl.lit(1).alias(\"alt_id\"),\n",
    "            pl.lit(\"Constant\").alias(\"dt_choice.type\"),\n",
    "            ((pl.col(\"plan_id\")*100).cast(pl.Utf8)+ pl.col(\"tour_id\").cast(pl.Utf8))\n",
    "            .cast(pl.Int64).alias(\"agent_id\")]) # agent_id ={plan_id*100;tour_id}\n",
    "    )\n",
    "    \n",
    "    # Prep next trip for additional stopping times\n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .with_columns([\n",
    "            # Get class.type of next trip within each agent\n",
    "            pl.col(\"class.type\")\n",
    "            .shift(-1)\n",
    "            .over(\"agent_id\")\n",
    "            .alias(\"next_class_type\")])\n",
    "    )\n",
    "    \n",
    "        # Prep next trip for additional stopping times\n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .with_columns([\n",
    "        # Add 1 to stopping_time if the next trip is of type \"Road\"\n",
    "            pl.when(\n",
    "                pl.col(\"stopping_time\").is_not_null() &\n",
    "                (pl.col(\"next_class_type\") == \"Road\")\n",
    "            )\n",
    "            .then(pl.col(\"stopping_time\") + 2)\n",
    "            .otherwise(pl.col(\"stopping_time\"))\n",
    "            .alias(\"stopping_time\")\n",
    "        ])\n",
    "        # Select columns\n",
    "        .select(['agent_id', 'alt_id', 'trip_id',\n",
    "                 'class.type', 'class.origin', 'class.destination', 'class.vehicle', 'class.route', \n",
    "                 'class.travel_time', 'stopping_time', 'dt_choice.type', 'dt_choice.departure_time'\n",
    "                ])\n",
    "    )\n",
    "    \n",
    "            \n",
    "                \n",
    "    return metro_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1775d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MATSim trips\n",
    "matsim_trips = pl.read_parquet(MATSIM_TRIPS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d92c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_trips = generate_trips(matsim_trips, edges, vehicles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef133a",
   "metadata": {},
   "source": [
    "# Format Supply for Metropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad05b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_supply(edges, vehicles):\n",
    "    edges = edges.drop([\"MATSim_id\"])\n",
    "    vehicles = vehicles.drop([\"vehicle_type\"])    \n",
    "    return [edges, vehicles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da6f2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "supply = format_supply(edges, vehicles)\n",
    "edges_df = supply[0]\n",
    "vehicles_df = supply[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "604f8a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing files to  /Users/andre/Desktop/Cergy/Python_Scripts/runs/pt_10pct/metro_inputs/\n"
     ]
    }
   ],
   "source": [
    "# Writing supply files\n",
    "print(\"Writing files to \", METRO_INPUT)\n",
    "edges_df.write_parquet(METRO_INPUT + \"edges.parquet\")\n",
    "vehicles_df.write_parquet(METRO_INPUT + \"vehicles.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821691c8",
   "metadata": {},
   "source": [
    "# Format Demand for Metropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b134bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_demand(trips):\n",
    "    \n",
    "    # format trips\n",
    "    # Eliminate trips departing after 48 hours\n",
    "    trips = trips.filter(pl.col(\"dt_choice.departure_time\") <= 108000,\n",
    "                         ~((pl.col(\"class.type\") == \"Road\") &\n",
    "                           (pl.col(\"class.origin\").is_null()|pl.col(\"class.destination\").is_null())\n",
    "                          ))\n",
    "            \n",
    "    # format agents\n",
    "    agents = trips.select(\"agent_id\").unique().with_columns([\n",
    "        pl.lit(\"Deterministic\").alias(\"alt_choice.type\"),\n",
    "        pl.lit(0.0).alias(\"alt_choice.u\"),\n",
    "        pl.lit(None).alias(\"alt_choice.mu\")\n",
    "    ]).sort(\"agent_id\")\n",
    "\n",
    "    # format alts\n",
    "    alts = (\n",
    "        trips.sort(\"dt_choice.departure_time\")\n",
    "        .unique(subset=[\"agent_id\"], keep=\"first\")\n",
    "        .select([\n",
    "            \"agent_id\",\n",
    "            \"alt_id\",\n",
    "            pl.lit(None).alias(\"origin_delay\"),\n",
    "            pl.col(\"dt_choice.type\"),\n",
    "            \"dt_choice.departure_time\",\n",
    "\n",
    "            pl.lit(None).alias(\"dt_choice.interval\"),\n",
    "            pl.lit(None).alias(\"dt_choice.model.type\"),\n",
    "            pl.lit(0.0).alias(\"dt_choice.model.u\"),\n",
    "            pl.lit(0.0).alias(\"dt_choice.model.mu\"),\n",
    "            pl.lit(None).alias(\"dt_choice.offset\"),\n",
    "\n",
    "            pl.lit(0.0).alias(\"constant_utility\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.one\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.two\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.three\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.four\"),\n",
    "\n",
    "            pl.lit(None).alias(\"origin_utility.type\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.tstar\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.beta\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.gamma\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.delta\"),\n",
    "\n",
    "            pl.lit(None).alias(\"destination_utility.type\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.tstar\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.beta\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.gamma\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.delta\"),\n",
    "\n",
    "            pl.lit(True).alias(\"pre_compute_route\")\n",
    "        ])\n",
    "    )\n",
    "    alts = alts.sort(\"agent_id\")\n",
    "    \n",
    "    trips = trips.drop([\"dt_choice.type\", \"dt_choice.departure_time\"])\n",
    "\n",
    "    \n",
    "    return agents, alts, trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287b271",
   "metadata": {},
   "source": [
    "# Write Metro input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19e05a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Metropolis parameters\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "print(\"Writing Metropolis parameters\")\n",
    "with open(os.path.join(METRO_INPUT, \"parameters.json\"), \"w\") as f:\n",
    "    f.write(json.dumps(PARAMETERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee82b8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Metropolis supply in  /Users/andre/Desktop/Cergy/Python_Scripts/runs/pt_10pct/metro_inputs/\n"
     ]
    }
   ],
   "source": [
    "# Writing files\n",
    "print(\"Writing Metropolis supply in \", METRO_INPUT)\n",
    "edges_df.write_parquet(METRO_INPUT + \"edges.parquet\")\n",
    "vehicles_df.write_parquet(METRO_INPUT + \"vehicles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03e34282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Formating\n",
    "agents_df = format_demand(metro_trips)[0]\n",
    "alts_df = format_demand(metro_trips)[1]\n",
    "trips_df = format_demand(metro_trips)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbcf87f",
   "metadata": {},
   "source": [
    "## +1 sec de marche à pied pour les freight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d8e55",
   "metadata": {},
   "source": [
    "### Freight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "504ae4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "freight_agents = trips_df.filter(pl.col(\"class.vehicle\") == 3).select(\"agent_id\").unique()\n",
    "\n",
    "trips_df = trips_df.with_columns([\n",
    "    pl.when(\n",
    "        pl.col(\"agent_id\").is_in(freight_agents[\"agent_id\"]) &\n",
    "        pl.col(\"class.travel_time\").is_not_null()\n",
    "    )\n",
    "    .then(pl.max_horizontal([pl.col(\"class.travel_time\"), pl.lit(1)]))\n",
    "    .otherwise(pl.col(\"class.travel_time\"))\n",
    "    .alias(\"class.travel_time\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903317a",
   "metadata": {},
   "source": [
    "# Write Demand Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8ff158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agents_df=agents_df.sample(fraction= 1, with_replacement=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d30e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = trips_df.with_columns(pl.lit(None).alias(\"class.route\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b86151a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_991_343, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>agent_id</th><th>alt_id</th><th>trip_id</th><th>class.type</th><th>class.origin</th><th>class.destination</th><th>class.vehicle</th><th>class.route</th><th>class.travel_time</th><th>stopping_time</th></tr><tr><td>i64</td><td>i32</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>null</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>&quot;Virtual&quot;</td><td>158987061</td><td>null</td><td>null</td><td>null</td><td>603.0</td><td>0.0</td></tr><tr><td>1</td><td>1</td><td>2</td><td>&quot;Virtual&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2542.0</td><td>0.0</td></tr><tr><td>1</td><td>1</td><td>3</td><td>&quot;Virtual&quot;</td><td>null</td><td>26646233</td><td>null</td><td>null</td><td>495.0</td><td>30953.0</td></tr><tr><td>2</td><td>1</td><td>4</td><td>&quot;Virtual&quot;</td><td>26646233</td><td>null</td><td>null</td><td>null</td><td>495.0</td><td>0.0</td></tr><tr><td>2</td><td>1</td><td>5</td><td>&quot;Virtual&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2197.0</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>526110001</td><td>1</td><td>2</td><td>&quot;Road&quot;</td><td>101473666</td><td>6171409038</td><td>0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>526110001</td><td>1</td><td>3</td><td>&quot;Virtual&quot;</td><td>6171409038</td><td>6171409038</td><td>null</td><td>null</td><td>0.0</td><td>3765.0</td></tr><tr><td>526110001</td><td>1</td><td>4</td><td>&quot;Virtual&quot;</td><td>6171409038</td><td>6171409038</td><td>null</td><td>null</td><td>0.0</td><td>2.0</td></tr><tr><td>526110001</td><td>1</td><td>5</td><td>&quot;Road&quot;</td><td>6171409038</td><td>101473666</td><td>0</td><td>null</td><td>null</td><td>0.0</td></tr><tr><td>526110001</td><td>1</td><td>6</td><td>&quot;Virtual&quot;</td><td>101473666</td><td>101473666</td><td>null</td><td>null</td><td>0.0</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_991_343, 10)\n",
       "┌───────────┬────────┬─────────┬────────────┬───┬────────────┬────────────┬────────────┬───────────┐\n",
       "│ agent_id  ┆ alt_id ┆ trip_id ┆ class.type ┆ … ┆ class.vehi ┆ class.rout ┆ class.trav ┆ stopping_ │\n",
       "│ ---       ┆ ---    ┆ ---     ┆ ---        ┆   ┆ cle        ┆ e          ┆ el_time    ┆ time      │\n",
       "│ i64       ┆ i32    ┆ i64     ┆ str        ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---       │\n",
       "│           ┆        ┆         ┆            ┆   ┆ i64        ┆ null       ┆ f64        ┆ f64       │\n",
       "╞═══════════╪════════╪═════════╪════════════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n",
       "│ 1         ┆ 1      ┆ 1       ┆ Virtual    ┆ … ┆ null       ┆ null       ┆ 603.0      ┆ 0.0       │\n",
       "│ 1         ┆ 1      ┆ 2       ┆ Virtual    ┆ … ┆ null       ┆ null       ┆ 2542.0     ┆ 0.0       │\n",
       "│ 1         ┆ 1      ┆ 3       ┆ Virtual    ┆ … ┆ null       ┆ null       ┆ 495.0      ┆ 30953.0   │\n",
       "│ 2         ┆ 1      ┆ 4       ┆ Virtual    ┆ … ┆ null       ┆ null       ┆ 495.0      ┆ 0.0       │\n",
       "│ 2         ┆ 1      ┆ 5       ┆ Virtual    ┆ … ┆ null       ┆ null       ┆ 2197.0     ┆ 0.0       │\n",
       "│ …         ┆ …      ┆ …       ┆ …          ┆ … ┆ …          ┆ …          ┆ …          ┆ …         │\n",
       "│ 526110001 ┆ 1      ┆ 2       ┆ Road       ┆ … ┆ 0          ┆ null       ┆ null       ┆ 0.0       │\n",
       "│ 526110001 ┆ 1      ┆ 3       ┆ Virtual    ┆ … ┆ null       ┆ null       ┆ 0.0        ┆ 3765.0    │\n",
       "│ 526110001 ┆ 1      ┆ 4       ┆ Virtual    ┆ … ┆ null       ┆ null       ┆ 0.0        ┆ 2.0       │\n",
       "│ 526110001 ┆ 1      ┆ 5       ┆ Road       ┆ … ┆ 0          ┆ null       ┆ null       ┆ 0.0       │\n",
       "│ 526110001 ┆ 1      ┆ 6       ┆ Virtual    ┆ … ┆ null       ┆ null       ┆ 0.0        ┆ null      │\n",
       "└───────────┴────────┴─────────┴────────────┴───┴────────────┴────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "487701ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Metropolis input to /Users/andre/Desktop/Cergy/Python_Scripts/runs/pt_10pct/metro_inputs/\n",
      "Writing Metropolis agents\n",
      "Writing Metropolis alternatives\n",
      "Writing Metropolis trips\n",
      "Input files have been successfully written\n"
     ]
    }
   ],
   "source": [
    "# Writing files\n",
    "print(\"Writing Metropolis input to\", METRO_INPUT)\n",
    "\n",
    "print(\"Writing Metropolis agents\")\n",
    "agents_df.write_parquet(METRO_INPUT + \"agents.parquet\")\n",
    "\n",
    "print(\"Writing Metropolis alternatives\")\n",
    "alts_df.write_parquet(METRO_INPUT + \"alts.parquet\")\n",
    "\n",
    "print(\"Writing Metropolis trips\")\n",
    "trips_df.write_parquet(METRO_INPUT + \"trips.parquet\")\n",
    "print(\"Input files have been successfully written\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
