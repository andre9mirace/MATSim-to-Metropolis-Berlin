{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e50908",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6eb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pyarrow\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import mpl_utils\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from xopen import xopen\n",
    "from datetime import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab378f67",
   "metadata": {},
   "source": [
    "## Set-up Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_directory = '/Users/andre/Desktop/Cergy/'\n",
    "\n",
    "berlin_driectory = 'MATSim/matsim-berlin/input/v6.4/'\n",
    "\n",
    "pt_10pct_dir = 'Python_Scripts/runs/pt_10pct/'\n",
    "\n",
    "# supply paths\n",
    "NETWORK_PATH = (os.path.join(general_directory, berlin_driectory, \"berlin-v6.4-network.xml.gz\"))\n",
    "VEHICLE_PATH = (os.path.join(general_directory, berlin_driectory, \"berlin-v6.4-vehicleTypes.xml\"))\n",
    "\n",
    "# demand path\n",
    "NETWORK_PATH = (os.path.join(general_directory, berlin_driectory, \"berlin-v6.4.output_plans.xml.gz\"))\n",
    "\n",
    "# metropolis path\n",
    "METRO_INPUT = (os.path.join(general_directory, pt_10pct_dir, \"metro_inputs/\"))\n",
    "METRO_OUTPUT = (os.path.join(general_directory, pt_10pct_dir, \"metro_outputs/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hhmmss_str_to_seconds_expr(col: str) -> pl.Expr:\n",
    "    return (\n",
    "        pl.col(col)\n",
    "        .map_elements(\n",
    "            lambda t: sum(x * m for x, m in zip(map(int, str(t).split(\":\")), [3600, 60, 1]))\n",
    "            if isinstance(t, str) and \":\" in t else None,\n",
    "            return_dtype=pl.Int32\n",
    "        )\n",
    "        .alias(f\"{col}_secs\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda369b",
   "metadata": {},
   "source": [
    "# Config and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86370c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SHARE = 0.10 # 10% of total population to match MATSim Berlin\n",
    "\n",
    "# Parameters to use for the simulation.\n",
    "PARAMETERS ={\n",
    "    \"input_files\": {\n",
    "      \"agents\": (os.path.join(METRO_INPUT, \"agents.parquet\")) ,\n",
    "      \"alternatives\": (os.path.join(METRO_INPUT, \"alts.parquet\")),\n",
    "      \"trips\": (os.path.join(METRO_INPUT, \"trips.parquet\")),\n",
    "      \"edges\": (os.path.join(METRO_INPUT, \"edges.parquet\")),\n",
    "      \"vehicle_types\": (os.path.join(METRO_INPUT, \"vehicles.parquet\"))\n",
    "                },\n",
    "    \"output_directory\": METRO_OUTPUT,\n",
    "    \"period\": [0.0, 86400.0],\n",
    "    \"road_network\": {\n",
    "        \"recording_interval\": 950.0,\n",
    "        \"approximation_bound\": 1.0,\n",
    "        \"spillback\": True,\n",
    "        \"backward_wave_speed\": 15.0,\n",
    "        \"max_pending_duration\": 30.0,\n",
    "        \"constrain_inflow\": True,\n",
    "        \"algorithm_type\": \"Best\"\n",
    "    },\n",
    "    \"learning_model\": {\n",
    "      \"type\": \"Linear\"\n",
    "    },\n",
    "    \"init_iteration_counter\": 1,\n",
    "    \"max_iterations\": 1,\n",
    "    \"update_ratio\": 1.0,\n",
    "    \"random_seed\": 13081996,\n",
    "    \"nb_threads\": 16,\n",
    "    \"saving_format\": \"Parquet\",\n",
    "    \"only_compute_decisions\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ad3d5",
   "metadata": {},
   "source": [
    "# Read MATSim output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f291bb",
   "metadata": {},
   "source": [
    "# Supply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ab565",
   "metadata": {},
   "source": [
    "## Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb81eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_reader(vehcile_path):\n",
    "    tree = ET.iterparse(xopen(vehcile_path, \"r\"), events=[\"start\", \"end\"])\n",
    "    vehicle_types = []\n",
    "    current_vehicle_type = {}\n",
    "    is_parsing_vehicle_type = False\n",
    "    for xml_event, elem in tree:\n",
    "        _, _, elem_tag = elem.tag.partition(\"}\")  # Removing xmlns tag from tag name\n",
    "        # VEHICLETYPES\n",
    "        if elem_tag == \"vehicleType\" and xml_event == \"start\":\n",
    "            parse_attributes(elem, current_vehicle_type)\n",
    "            is_parsing_vehicle_type = True\n",
    "        # ATTRIBUTES\n",
    "        elif elem_tag == \"attribute\" and xml_event == \"start\":\n",
    "            current_vehicle_type[elem.attrib[\"name\"]] = elem.text\n",
    "        # LENGTH / WIDTH\n",
    "        elif elem_tag in [\"length\", \"width\"] and xml_event == \"start\":\n",
    "            current_vehicle_type[elem_tag] = elem.attrib[\"meter\"]\n",
    "        # VEHICLETYPES\n",
    "        elif elem_tag == \"vehicleType\" and xml_event == \"end\":\n",
    "            vehicle_types.append(current_vehicle_type)\n",
    "            current_vehicle_type = {}\n",
    "            elem.clear()\n",
    "            is_parsing_vehicle_type = False\n",
    "        # EVERYTHING ELSE\n",
    "        elif is_parsing_vehicle_type and elem_tag not in [\"attribute\", \"length\", \"width\"]:\n",
    "            parse_attributes(elem, current_vehicle_type)\n",
    "    vehicle_types = pd.DataFrame.from_records(vehicle_types)\n",
    "    col_types = {\n",
    "        \"accessTimeInSecondsPerPerson\": float,\n",
    "        \"egressTimeInSecondsPerPerson\": float,\n",
    "        \"seats\": int,\n",
    "        \"standingRoomInPersons\": int,\n",
    "        \"length\": float,\n",
    "        \"width\": float,\n",
    "        \"pce\": float,\n",
    "        \"factor\": float,\n",
    "    }\n",
    "    for col, dtype in col_types.items():\n",
    "        if col in vehicle_types.columns:\n",
    "            try:\n",
    "                vehicle_types[col] = vehicle_types[col].astype(dtype)\n",
    "            except:\n",
    "                print(f\"dataframe types conversion failed for column {col}\")\n",
    "    return vehicle_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3016b",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_network(network_path):\n",
    "    tree = ET.iterparse(xopen(network_path, \"r\"), events=[\"start\", \"end\"])\n",
    "    links = []\n",
    "    \n",
    "    for xml_event, elem in tree:\n",
    "        \n",
    "        \n",
    "                \n",
    "        if elem.tag == \"link\" and xml_event == \"start\":\n",
    "            atts = elem.attrib\n",
    "            \n",
    "            # Remove '#' from link_id\n",
    "            atts[\"link_id\"] = atts[\"id\"].replace(\"#\", \"\")\n",
    "            atts[\"numeric_link_id\"] = int(atts[\"id\"].split(\"#\")[0])            \n",
    "            \n",
    "            atts[\"from_node\"] = atts.pop(\"from\")\n",
    "            atts[\"to_node\"] = atts.pop(\"to\")\n",
    "             \n",
    "            if \"cluster\" in atts[\"from_node\"]:\n",
    "                atts[\"from_node\"] = atts[\"from_node\"].replace(\"cluster_\", \"\").split(\"_\")[0]\n",
    "            if \"cluster\" in atts[\"to_node\"]:\n",
    "                atts[\"to_node\"] = atts[\"to_node\"].replace(\"cluster_\", \"\").split(\"_\")[0]\n",
    "            \n",
    "            \n",
    "            atts[\"length\"] = float(atts[\"length\"])\n",
    "            atts[\"freespeed\"] = float(atts[\"freespeed\"])\n",
    "            atts[\"capacity\"] = float(atts[\"capacity\"])\n",
    "            atts[\"permlanes\"] = float(atts[\"permlanes\"])\n",
    "            \n",
    "            if \"volume\" in atts:\n",
    "                atts[\"volume\"] = float(atts[\"volume\"])\n",
    "                \n",
    "            links.append(atts)\n",
    "            \n",
    "        # clear the element when we're done, to keep memory usage low\n",
    "        if elem.tag in [\"node\", \"link\"] and xml_event == \"end\":\n",
    "            elem.clear()\n",
    "            \n",
    "    links = pd.DataFrame.from_records(links)\n",
    "    links = links.loc[links[\"modes\"].str.contains(\"car\")].copy()\n",
    "    links[\"link_id\"] = links[\"link_id\"].astype(int)\n",
    "    links[\"from_node\"] = links[\"from_node\"].astype(int)\n",
    "    links[\"to_node\"] = links[\"to_node\"].astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_pair_counts = links[[\"from_node\", \"to_node\"]].value_counts()\n",
    "    if node_pair_counts.max() > 2:\n",
    "        print(\"More than two parallel edges\")\n",
    "        \n",
    "    parallel_idx = node_pair_counts.loc[node_pair_counts > 1].index\n",
    "    if len(parallel_idx):\n",
    "        print(\"Found {} parallel edges\".format(len(parallel_idx)))\n",
    "        next_node_id = max(links[\"from_node\"].max(), links[\"to_node\"].max()) + 1\n",
    "        next_link_id = links[\"link_id\"].max() + 1\n",
    "        new_rows = list()\n",
    "        for (source, target) in parallel_idx:\n",
    "            mask = (links[\"from_node\"] == source) & (links[\"to_node\"] == target)\n",
    "            idx = mask[mask].index\n",
    "            row = links.loc[idx[1]].copy()\n",
    "            row[\"length\"] = 0.0\n",
    "            row[\"from_node\"] = next_node_id\n",
    "            row[\"link_id\"] = next_link_id\n",
    "            new_rows.append(row)\n",
    "            links.loc[idx[1], \"to_node\"] = next_node_id\n",
    "            next_link_id += 1\n",
    "            next_node_id += 1\n",
    "        links = pd.concat((links, pd.DataFrame(new_rows)))\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311c34e",
   "metadata": {},
   "source": [
    "# Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080ba22",
   "metadata": {},
   "source": [
    "### Read `output_plans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_reader_dataframe(plan_path, selected_plans_only=True):\n",
    "    \n",
    "    tree = ET.iterparse(xopen(plan_path), events=[\"start\", \"end\"])\n",
    "    persons = []\n",
    "    plans = []\n",
    "    activities = []\n",
    "    legs = []\n",
    "    routes = []\n",
    "    current_person = {}\n",
    "    current_plan = {}\n",
    "    current_activity = {}\n",
    "    current_leg = {}\n",
    "    current_route = {}\n",
    "    current_person = {}\n",
    "    current_plan = {}\n",
    "    current_activity = {}\n",
    "    current_leg = {}\n",
    "    current_route = {}\n",
    "\n",
    "    is_parsing_person = False\n",
    "    is_parsing_activity = False\n",
    "    is_parsing_leg = False\n",
    "    is_selected_plan = True\n",
    "\n",
    "    current_person_id = None\n",
    "    current_plan_id = 0\n",
    "    current_activity_id = 0\n",
    "    current_leg_id = 0\n",
    "    current_route_id = 0\n",
    "\n",
    "    for xml_event, elem in tree:\n",
    "        if xml_event == \"start\":\n",
    "            \n",
    "            if elem.tag == \"person\":\n",
    "                current_person[\"id\"] = elem.attrib[\"id\"]\n",
    "                current_person_id = elem.attrib[\"id\"]\n",
    "                is_parsing_person = True\n",
    "            \n",
    "            # PLAN\n",
    "            if elem.tag == \"plan\":\n",
    "                is_selected_plan = not selected_plans_only or elem.attrib.get(\"selected\", \"no\") == \"yes\"\n",
    "                if not is_selected_plan:\n",
    "                    continue\n",
    "                current_plan[\"id\"] = current_plan_id\n",
    "                current_plan[\"person_id\"] = current_person_id\n",
    "                current_plan_id += 1\n",
    "                parse_attributes(elem, current_plan)\n",
    "\n",
    "            # ACTIVITY\n",
    "            elif elem.tag == \"activity\" and is_selected_plan:\n",
    "                is_parsing_activity = True\n",
    "                current_activity_id += 1\n",
    "                current_activity[\"id\"] = current_activity_id\n",
    "                current_activity[\"plan_id\"] = current_plan_id-1\n",
    "                parse_attributes(elem, current_activity)\n",
    "\n",
    "            # LEG\n",
    "            elif elem.tag == \"leg\" and is_selected_plan:\n",
    "                is_parsing_leg = True\n",
    "                current_leg_id += 1\n",
    "                current_leg[\"id\"] = current_leg_id\n",
    "                current_leg[\"plan_id\"] = current_plan_id-1\n",
    "                parse_attributes(elem, current_leg)\n",
    "\n",
    "            # ROUTE\n",
    "            elif elem.tag == \"route\" and is_selected_plan:\n",
    "                current_route_id += 1\n",
    "                current_route[\"id\"] = current_route_id\n",
    "                current_route[\"leg_id\"] = current_leg_id\n",
    "                parse_attributes(elem, current_route)\n",
    "        \n",
    "        elif xml_event == \"end\":\n",
    "            \n",
    "        # PERSON\n",
    "            if elem.tag == \"person\":\n",
    "                persons.append(current_person)\n",
    "                current_person = {}\n",
    "                is_parsing_person = False\n",
    "\n",
    "        \n",
    "        # PLAN \n",
    "            elif elem.tag == \"plan\" and is_selected_plan:\n",
    "                plans.append(current_plan)\n",
    "                current_plan = {}\n",
    "                \n",
    "         # ACTIVITY\n",
    "            elif elem.tag == \"activity\" and is_parsing_activity and is_selected_plan:\n",
    "                activities.append(current_activity)\n",
    "                current_activity = {}\n",
    "                is_parsing_activity = False\n",
    "                \n",
    "        # LEG\n",
    "            elif elem.tag == \"leg\" and is_parsing_leg and is_selected_plan:\n",
    "                legs.append(current_leg)\n",
    "                current_leg = {}\n",
    "                is_parsing_leg = False\n",
    "                \n",
    "        # ROUTE\n",
    "            elif elem.tag == \"route\" and is_selected_plan:\n",
    "                current_route[\"value\"] = elem.text\n",
    "                routes.append(current_route)\n",
    "                current_route = {}\n",
    "                \n",
    "            elif elem.tag == \"attribute\":\n",
    "                attribs = elem.attrib\n",
    "                if is_parsing_activity and is_selected_plan:\n",
    "                    current_activity[attribs[\"name\"]] = elem.text\n",
    "                elif is_parsing_leg and is_selected_plan:\n",
    "                    current_leg[attribs[\"name\"]] = elem.text\n",
    "                elif is_parsing_person:\n",
    "                    current_person[attribs[\"name\"]] = elem.text\n",
    "            elem.clear()\n",
    "\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    return (\n",
    "        pl.DataFrame(persons),\n",
    "        pl.DataFrame(plans),\n",
    "        pl.DataFrame(activities),\n",
    "        pl.DataFrame(legs),\n",
    "        pl.DataFrame(routes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eced646",
   "metadata": {},
   "source": [
    "# Convert MATSim output to Metropolis input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521ca91",
   "metadata": {},
   "source": [
    "# Supply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5de61a",
   "metadata": {},
   "source": [
    "## Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93951923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vehicles_df(vehicle_types):\n",
    "    vehicle_list = []\n",
    "\n",
    "    for idx, row in vehicle_types.iterrows():\n",
    "        if row[\"id\"] == \"ride\":\n",
    "            vehicle = {\n",
    "                \"vehicle_id\": idx,\n",
    "                \"vehicle_type\": row[\"id\"],\n",
    "                \"headway\": float(row[\"length\"]),\n",
    "                \"pce\": 0.0,\n",
    "                \"speed_function.type\": \"Base\",\n",
    "                \"speed_function.upper_bound\": None,\n",
    "                \"speed_function.coef\": None,\n",
    "            }\n",
    "        else:\n",
    "            vehicle = {\n",
    "                \"vehicle_id\": idx,\n",
    "                \"vehicle_type\": row[\"id\"],\n",
    "                \"headway\": float(row[\"length\"]),\n",
    "                \"pce\": float(row[\"pce\"]) / POPULATION_SHARE, \n",
    "                \"speed_function.type\": \"Base\",\n",
    "                \"speed_function.upper_bound\": None,\n",
    "                \"speed_function.coef\": None,\n",
    "            }\n",
    "        vehicle_list.append(vehicle)\n",
    "\n",
    "    vehicles = pl.DataFrame(vehicle_list)\n",
    "    vehicles = vehicles.filter(pl.col('vehicle_id')<5) # vehicles in the sim: car, bike, ride, truck, freight\n",
    "    return vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc1911",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edges_df(links, alpha=1): # lower alpha for increased congestion\n",
    "    edge_list = []\n",
    "\n",
    "    for i, (_, row) in enumerate(links.iterrows()):\n",
    "        edge = {\n",
    "            \"edge_id\": i+1,\n",
    "            \"MATSim_id\": row[\"id\"],\n",
    "            \"source\": int(row[\"from_node\"]),\n",
    "            \"target\": int(row[\"to_node\"]),\n",
    "            \"speed\": float(row[\"freespeed\"]),\n",
    "            \"length\": float(row[\"length\"]),\n",
    "            \"lanes\": float(row[\"permlanes\"]),\n",
    "            \"speed_density.type\": \"FreeFlow\",\n",
    "            \"speed_density.capacity\": None,\n",
    "            \"speed_density.min_density\": None,\n",
    "            \"speed_density.jam_density\": None,\n",
    "            \"speed_density.jam_speed\": None,\n",
    "            \"speed_density.beta\": None,\n",
    "            # capacity per lane in vehicles per hour bc MATSim gives capacity per edge (all lanes included) while Metropolis considers 1 lane = 1 edge\n",
    "            \"bottleneck_flow\": float(row[\"capacity\"])*alpha/ (row['permlanes']*3600.0),  \n",
    "            # MATSim handles time as 1-second steps. METROPOLIS handles time as a continuous -> We add a supplementary second to the tt\n",
    "            \"constant_travel_time\": math.ceil(float(row[\"length\"]) / float(row[\"freespeed\"])) - float(row[\"length\"]) / float(row[\"freespeed\"]),\n",
    "            \"overtaking\": True\n",
    "        }\n",
    "        edge_list.append(edge)\n",
    "\n",
    "    edges = pl.DataFrame(edge_list)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c28765c",
   "metadata": {},
   "source": [
    "# Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence (activities, legs, routes):\n",
    "    legs = (legs\n",
    "        .join(routes, how='left', left_on='id', right_on='leg_id')\n",
    "        .with_columns(pl.col('id').alias('leg_id'),\n",
    "                      hhmmss_str_to_seconds_expr(\"dep_time\")))\n",
    "\n",
    "    activities = (activities\n",
    "                  .drop([\"facility\", \"initialEndTime\", \"orig_duration\"])\n",
    "                  .with_columns([\n",
    "                      hhmmss_str_to_seconds_expr(\"end_time\"),\n",
    "                      hhmmss_str_to_seconds_expr(\"max_dur\")#,\n",
    "                      #hhmmss_str_to_seconds_expr(\"trav_time\")\n",
    "                  ])\n",
    "                 )\n",
    "    \n",
    "    # pair seq IDs for activities\n",
    "    activities = activities.with_columns([\n",
    "        ((pl.cum_count(\"plan_id\").over(\"plan_id\") - 1) * 2).alias('seq_index'),\n",
    "        pl.lit('activity').alias('element_type'),\n",
    "        pl.col('type').alias('type_or_mode'),\n",
    "        hhmmss_str_to_seconds_expr(\"max_dur\").cast(pl.Float64).alias(\"duration\"),\n",
    "        pl.col('link').alias('route'),\n",
    "        pl.col('link').alias('start_link'),\n",
    "        pl.col('link').alias('end_link')\n",
    "    ])\n",
    "\n",
    "    # odd seq IDs for legs\n",
    "    legs = legs.with_columns([\n",
    "        ((pl.cum_count(\"plan_id\").over(\"plan_id\") - 1) * 2 + 1).alias('seq_index'),\n",
    "        pl.lit('leg').alias('element_type'),\n",
    "        pl.col('mode').alias('type_or_mode'),\n",
    "        pl.col('trav_time').alias('duration'),\n",
    "        pl.col('value').alias('route')\n",
    "                             ])\n",
    "    activities_secs = activities.select([\n",
    "    \"plan_id\",\n",
    "    ((pl.cum_count(\"plan_id\").over(\"plan_id\") - 1) * 2).alias(\"seq_index\"),\n",
    "    \"end_time_secs\",\n",
    "    \"max_dur_secs\",\n",
    "    pl.lit(None).cast(pl.Int32).alias(\"dep_time_secs\"),\n",
    "    pl.lit(None).cast(pl.Float64).alias(\"trav_time_secs\")\n",
    "    ])\n",
    "    \n",
    "    legs_secs = legs.select([\n",
    "    \"plan_id\",\n",
    "    ((pl.cum_count(\"plan_id\").over(\"plan_id\") - 1) * 2 + 1).alias(\"seq_index\"),\n",
    "    pl.lit(None).cast(pl.Int32).alias(\"end_time_secs\"),\n",
    "    pl.lit(None).cast(pl.Int32).alias(\"max_dur_secs\"),\n",
    "    \"dep_time_secs\",\n",
    "    pl.col(\"trav_time\").alias('trav_time_secs')\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    extra_cols = pl.concat([activities_secs, legs_secs])\n",
    "    clean_cols = [\"plan_id\", \"seq_index\", \"element_type\", \"type_or_mode\", \"start_link\",\n",
    "                  \"end_link\", \"route\", \"duration\"]\n",
    "\n",
    "    activities_clean = activities.select(clean_cols)\n",
    "    legs_clean = legs.select(clean_cols)\n",
    "    \n",
    "    matsim_trips = pl.concat([activities_clean, legs_clean]).sort(['plan_id', 'seq_index'])\n",
    "\n",
    "    matsim_trips = matsim_trips.with_columns([\n",
    "        # Indicate if activity is not interaction\n",
    "        ((pl.col('element_type') == 'leg'))\n",
    "        .cast(pl.Int8).alias('is_trip_start')\n",
    "    ])\n",
    "\n",
    "    matsim_trips = (matsim_trips\n",
    "                    .with_columns([pl.col('is_trip_start').cum_sum().over('plan_id').alias('trip_id')])\n",
    "                    .drop('is_trip_start')\n",
    "                    .join(extra_cols, on=[\"plan_id\", \"seq_index\"], how=\"left\")\n",
    "        )\n",
    "    \n",
    "    # Record start and end times for activities and legs\n",
    "    matsim_trips = matsim_trips.with_columns([\n",
    "    pl.col(\"dep_time_secs\").shift(1).alias(\"prev_leg_dep_secs\"),\n",
    "    pl.col(\"trav_time_secs\").shift(1).alias(\"prev_leg_trav_secs\"),\n",
    "    ])\n",
    "\n",
    "    # Activity duration\n",
    "    matsim_trips = matsim_trips.with_columns([\n",
    "        pl.when((pl.col(\"element_type\") == \"activity\") & pl.col(\"max_dur_secs\").is_not_null())\n",
    "          .then(pl.col(\"max_dur_secs\"))\n",
    "\n",
    "        .when((pl.col(\"element_type\") == \"activity\") &\n",
    "              pl.col(\"end_time_secs\").is_not_null() &\n",
    "              pl.col(\"prev_leg_dep_secs\").is_not_null() &\n",
    "              pl.col(\"prev_leg_trav_secs\").is_not_null())\n",
    "          .then(pl.col(\"end_time_secs\") - (pl.col(\"prev_leg_dep_secs\") + pl.col(\"prev_leg_trav_secs\")))\n",
    "\n",
    "        .otherwise(None)\n",
    "        .alias(\"activity_duration_secs\")\n",
    "    ])\n",
    "    # Gather \"activity_duration\" and \"travel_time\" into a single variable\n",
    "    matsim_trips = matsim_trips.with_columns([\n",
    "        pl.when(pl.col(\"element_type\") == \"activity\")\n",
    "          .then(pl.col(\"activity_duration_secs\"))\n",
    "          .when(pl.col(\"element_type\") == \"leg\")\n",
    "          .then(pl.col(\"trav_time_secs\"))\n",
    "          .otherwise(None)\n",
    "          .alias(\"duration\")\n",
    "    ])\n",
    "\n",
    "    # get arrival time for legs\n",
    "    matsim_trips = matsim_trips.with_columns((pl.col('dep_time_secs')+pl.col('duration')).alias('arrival_time'))\n",
    "    \n",
    "    # Start times\n",
    "    matsim_trips = matsim_trips.with_columns([\n",
    "        pl.when(pl.col(\"element_type\") == \"leg\")\n",
    "          .then(pl.col(\"dep_time_secs\"))\n",
    "\n",
    "        .when((pl.col(\"element_type\") == \"activity\") & pl.col(\"end_time_secs\").is_not_null())\n",
    "          .then(pl.col(\"end_time_secs\") - pl.col(\"duration\"))\n",
    "\n",
    "        .when((pl.col(\"element_type\") == \"activity\") & pl.col(\"prev_leg_dep_secs\").is_not_null())\n",
    "          .then(pl.col(\"prev_leg_dep_secs\") + pl.col(\"prev_leg_trav_secs\"))\n",
    "\n",
    "        .otherwise(None)\n",
    "        .alias(\"start_time_secs\")\n",
    "    ])\n",
    "\n",
    "    # End times\n",
    "    matsim_trips = (\n",
    "        matsim_trips\n",
    "        .with_columns([\n",
    "        pl.when(pl.col(\"element_type\") == \"leg\")\n",
    "          .then(pl.col(\"dep_time_secs\") + pl.col(\"duration\"))\n",
    "        .when(pl.col(\"element_type\") == \"activity\")\n",
    "          .then(pl.col(\"start_time_secs\") + pl.col(\"duration\"))\n",
    "        .otherwise(None)\n",
    "        .alias(\"end_time_secs\")])\n",
    "        .join(plans.select(['id', 'person_id']), how='left', left_on='plan_id', right_on='id')\n",
    "        .select(['person_id', \"plan_id\", \"trip_id\", \"seq_index\", \"element_type\", \"type_or_mode\", \n",
    "                                        \"start_time_secs\", \"end_time_secs\", \"duration\", \n",
    "                                        \"route\", \"start_link\", \"end_link\"])    # Select and rearrange variables\n",
    "\n",
    "    )\n",
    "    \n",
    "    # Define tours\n",
    "    # Record start and end times for activities and legs\n",
    "    # look for activiy types with an end_time\n",
    "    tour_anchor_types = (list(set(\n",
    "        activities.filter(pl.col(\"end_time\").is_not_null())\n",
    "        .select(\"type\").unique().to_series().to_list()\n",
    "    )))\n",
    "\n",
    "    # Add walking legs to separate walking legs in metropolis\n",
    "    tour_anchor_types = list(set(tour_anchor_types))\n",
    "\n",
    "    # Create a tour flag\n",
    "    matsim_trips = matsim_trips.with_columns([\n",
    "        pl.col(\"type_or_mode\").is_in(tour_anchor_types)\n",
    "        .alias(\"is_tour_anchor\")\n",
    "    ])\n",
    "\n",
    "    # Create tours\n",
    "    matsim_trips = matsim_trips.with_columns([\n",
    "        pl.col(\"is_tour_anchor\")\n",
    "          .cast(pl.Int32)\n",
    "          .cum_sum()\n",
    "          .over(\"plan_id\")\n",
    "          .alias(\"tour_id\")\n",
    "    ])\n",
    "    \n",
    "    # Define stopping times\n",
    "    stopping_time_df = (\n",
    "        matsim_trips\n",
    "        .filter(pl.col(\"element_type\") == \"activity\")\n",
    "        .with_columns([\n",
    "            pl.col(\"duration\").alias(\"stopping_time\")\n",
    "        ])\n",
    "        .sort(['plan_id', 'trip_id'])\n",
    "    )\n",
    "    \n",
    "    matsim_trips = (\n",
    "    matsim_trips\n",
    "    .filter(pl.col(\"element_type\") == \"leg\")\n",
    "    .rename({\"start_time_secs\":\"start_time\",\n",
    "             \"end_time_secs\": \"end_time\",\n",
    "             \"type_or_mode\":\"mode\"\n",
    "            })\n",
    "    .with_columns([\n",
    "        # Travel_time per trip\n",
    "        (pl.col(\"end_time\") - pl.col(\"start_time\")).alias(\"duration\")\n",
    "    ])\n",
    "    .select([\n",
    "        \"person_id\", \"plan_id\", \"tour_id\", \"trip_id\", \"seq_index\", \"mode\", \"start_time\", \"end_time\", \n",
    "        \"duration\", \"route\", \"start_link\", \"end_link\", \"stopping_time\"\n",
    "    ])\n",
    "    .sort([\"plan_id\", \"trip_id\", \"tour_id\"])\n",
    "    )\n",
    "    # Join stopping_time\n",
    "    matsim_trips = matsim_trips.join(stopping_time_df, on=[\"plan_id\", \"trip_id\"], how=\"left\")\n",
    "    \n",
    "    \n",
    "    return matsim_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff0c183",
   "metadata": {},
   "source": [
    "Define the criteria to filter out certain observations from the metropolis input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_trips(matsim_trips):\n",
    "    invalid_starts = (\n",
    "        matsim_trips\n",
    "        .filter(# no trips longer than 48 hours nor <0 activity duration\n",
    "            (pl.col(\"duration\") > 86400) | (pl.col(\"stopping_time\") < 0)\n",
    "        ) \n",
    "        .group_by(\"plan_id\")\n",
    "        .agg(pl.col(\"trip_id\").min().alias(\"first_invalid_trip\"))\n",
    "    )\n",
    "\n",
    "    trips_cleaned = (\n",
    "        matsim_trips\n",
    "        .join(invalid_starts, on=\"plan_id\", how=\"left\")\n",
    "        .filter(\n",
    "            (pl.col(\"first_invalid_trip\").is_null()) |  \n",
    "            (pl.col(\"trip_id\") < pl.col(\"first_invalid_trip\"))\n",
    "        )\n",
    "        .drop(\"first_invalid_trip\", \"duration_right\", 'route_right', 'start_link_right', 'end_link_right',\n",
    "              'person_id_right', 'tour_id_right', 'seq_index')\n",
    "    )\n",
    "    return trips_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48855d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trips(matsim_trips, edges, vehicles):\n",
    "    \n",
    "    # link (matsim) to edge (metro) dictionary\n",
    "    matsim_to_metro_links = dict(zip(edges[\"MATSim_id\"].cast(pl.Utf8), edges[\"edge_id\"]))\n",
    "    \n",
    "    metro_trips = matsim_trips\n",
    "    \n",
    "    # class.vehicle\n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .join(vehicles.select([\n",
    "            pl.col(\"vehicle_type\").alias(\"mode\"),\n",
    "            pl.col(\"vehicle_id\").alias(\"class.vehicle\")]),on=\"mode\", how=\"left\")\n",
    "        .with_columns([\n",
    "\n",
    "            # class.type\n",
    "            pl.when(pl.col(\"mode\").is_in(['truck', 'car', 'freight', 'ride']) # define Road trips\n",
    "                   )\n",
    "            .then(pl.lit(\"Road\"))\n",
    "            .otherwise(pl.lit(\"Virtual\"))\n",
    "            .alias(\"class.type\")])\n",
    "    )\n",
    "    \n",
    "    \n",
    "    metro_trips = (\n",
    "        \n",
    "    # class.type\n",
    "    metro_trips\n",
    "    .rename({'start_time':'dt_choice.departure_time'\n",
    "            })\n",
    "    .with_columns([\n",
    "                \n",
    "    # class.routes\n",
    "    pl.when(pl.col(\"class.type\") == \"Road\")\n",
    "      .then(pl.col(\"route\").str.split(\" \") # split route string\n",
    "            \n",
    "            # map in the dictionary\n",
    "            .map_elements(lambda link_list: None if link_list is None\n",
    "                          else [matsim_to_metro_links.get(link) for link in link_list[1:]],\n",
    "                          return_dtype=pl.List(pl.Int64))\n",
    "            .alias(\"class.route\"))\n",
    "      .otherwise(None),\n",
    "\n",
    "        \n",
    "    # class.travel_time\n",
    "    pl.when(pl.col(\"class.type\") == \"Road\")\n",
    "      .then(None)\n",
    "      .otherwise(pl.col(\"duration\"))\n",
    "    .alias(\"class.travel_time\")\n",
    "    ])\n",
    "    .drop(['person_id' , 'route', 'duration', 'end_time', 'mode'])\n",
    "    )\n",
    "    \n",
    "    # Define trips as starting at the target of the departure link and finsh at the target of the arrival_link\n",
    "    # Join with edges for start_link's from and to nodes\n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .join(\n",
    "            edges.select([\n",
    "                pl.col(\"MATSim_id\").alias(\"start_link\"),\n",
    "                pl.col(\"target\").alias(\"class.origin\")]), # class.origin\n",
    "            on=\"start_link\",how=\"left\")\n",
    "        .drop(pl.col('start_link'))\n",
    "        .join(\n",
    "            edges.select([\n",
    "                pl.col(\"MATSim_id\").alias(\"end_link\"),\n",
    "                pl.col(\"target\").alias(\"class.destination\")]), # class.destination\n",
    "            on=\"end_link\", how=\"left\")\n",
    "        .drop(pl.col('end_link'))\n",
    "    )\n",
    "    \n",
    "    \n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .with_columns([\n",
    "            pl.lit(1).alias(\"alt_id\"),\n",
    "            pl.lit(\"Constant\").alias(\"dt_choice.type\"),\n",
    "            ((pl.col(\"plan_id\")*100).cast(pl.Utf8)+ pl.col(\"tour_id\").cast(pl.Utf8))\n",
    "            .cast(pl.Int64).alias(\"agent_id\")]) # agent_id ={plan_id*100;tour_id}\n",
    "    )\n",
    "    \n",
    "    # Prep next trip for additional stopping times\n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .with_columns([\n",
    "            # Get class.type of next trip within each agent\n",
    "            pl.col(\"class.type\")\n",
    "            .shift(-1)\n",
    "            .over(\"agent_id\")\n",
    "            .alias(\"next_class_type\")])\n",
    "    )\n",
    "    \n",
    "        # Prep next trip for additional stopping times\n",
    "    metro_trips = (\n",
    "        metro_trips\n",
    "        .with_columns([\n",
    "        # Add +2 to stopping_time if the next trip is of type \"Road\"\n",
    "            pl.when(\n",
    "                pl.col(\"stopping_time\").is_not_null() &\n",
    "                (pl.col(\"next_class_type\") == \"Road\")\n",
    "            ) # +1 for person enters vehicle; +1 for 'vehicle_enters_trafic'\n",
    "            .then(pl.col(\"stopping_time\") + 2)         \n",
    "            .otherwise(pl.col(\"stopping_time\"))\n",
    "            .alias(\"stopping_time\")\n",
    "        ])\n",
    "        # Select columns\n",
    "        .select(['agent_id', 'alt_id', 'trip_id',\n",
    "                 'class.type', 'class.origin', 'class.destination', 'class.vehicle', 'class.route', \n",
    "                 'class.travel_time', 'stopping_time', 'dt_choice.type', 'dt_choice.departure_time'\n",
    "                ])\n",
    "    )\n",
    "    \n",
    "    # Set the minimal walking leg travel-time before a freight trip to 1 to match `output_events`\n",
    "    freight_agents = metro_trips.filter(pl.col(\"class.vehicle\") == 3).select(\"agent_id\").unique()\n",
    "    \n",
    "    metro_trips = metro_trips.with_columns([\n",
    "        pl.when(\n",
    "            pl.col(\"agent_id\").is_in(freight_agents[\"agent_id\"]) &\n",
    "            pl.col(\"class.travel_time\").is_not_null()\n",
    "        )\n",
    "        .then(pl.max_horizontal([pl.col(\"class.travel_time\"), pl.lit(1)])) # max (walking tt; 1) to avoid tt=0\n",
    "        .otherwise(pl.col(\"class.travel_time\"))\n",
    "        .alias(\"class.travel_time\")\n",
    "    ])\n",
    "            \n",
    "                \n",
    "    return metro_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb333a2",
   "metadata": {},
   "source": [
    "# Format Metropolis input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eff45f",
   "metadata": {},
   "source": [
    "## Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5499607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_supply(edges, vehicles):\n",
    "    edges = edges.drop([\"MATSim_id\"])\n",
    "    vehicles = vehicles.drop([\"vehicle_type\"])    \n",
    "    return [edges, vehicles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d63430",
   "metadata": {},
   "source": [
    "## Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_demand(trips):\n",
    "    \n",
    "    # format trips\n",
    "    # Eliminate trips departing after 48 hours\n",
    "    trips = trips.filter(pl.col(\"dt_choice.departure_time\") <= 108000,\n",
    "                         ~((pl.col(\"class.type\") == \"Road\") &\n",
    "                           (pl.col(\"class.origin\").is_null()|pl.col(\"class.destination\").is_null())\n",
    "                          ))\n",
    "            \n",
    "    # format agents\n",
    "    agents = trips.select(\"agent_id\").unique().with_columns([\n",
    "        pl.lit(\"Deterministic\").alias(\"alt_choice.type\"),\n",
    "        pl.lit(0.0).alias(\"alt_choice.u\"),\n",
    "        pl.lit(None).alias(\"alt_choice.mu\")\n",
    "    ]).sort(\"agent_id\")\n",
    "\n",
    "    # format alts\n",
    "    alts = (\n",
    "        trips.sort(\"dt_choice.departure_time\")\n",
    "        .unique(subset=[\"agent_id\"], keep=\"first\")\n",
    "        .select([\n",
    "            \"agent_id\",\n",
    "            \"alt_id\",\n",
    "            pl.lit(None).alias(\"origin_delay\"),\n",
    "            pl.col(\"dt_choice.type\"),\n",
    "            \"dt_choice.departure_time\",\n",
    "\n",
    "            pl.lit(None).alias(\"dt_choice.interval\"),\n",
    "            pl.lit(None).alias(\"dt_choice.model.type\"),\n",
    "            pl.lit(0.0).alias(\"dt_choice.model.u\"),\n",
    "            pl.lit(0.0).alias(\"dt_choice.model.mu\"),\n",
    "            pl.lit(None).alias(\"dt_choice.offset\"),\n",
    "\n",
    "            pl.lit(0.0).alias(\"constant_utility\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.one\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.two\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.three\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.four\"),\n",
    "\n",
    "            pl.lit(None).alias(\"origin_utility.type\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.tstar\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.beta\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.gamma\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.delta\"),\n",
    "\n",
    "            pl.lit(None).alias(\"destination_utility.type\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.tstar\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.beta\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.gamma\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.delta\"),\n",
    "\n",
    "            pl.lit(True).alias(\"pre_compute_route\")\n",
    "        ])\n",
    "    )\n",
    "    alts = alts.sort(\"agent_id\")\n",
    "    \n",
    "    trips = trips.drop([\"dt_choice.type\", \"dt_choice.departure_time\"])\n",
    "\n",
    "    \n",
    "    return agents, alts, trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdcabae",
   "metadata": {},
   "source": [
    "# Write Metropolis Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "print(\"Writing Metropolis parameters\")\n",
    "with open(os.path.join(METRO_INPUT, \"parameters.json\"), \"w\") as f:\n",
    "    f.write(json.dumps(PARAMETERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing files\n",
    "print(\"Writing Metropolis supply in \", METRO_INPUT)\n",
    "edges_df.write_parquet(METRO_INPUT + \"edges.parquet\")\n",
    "vehicles_df.write_parquet(METRO_INPUT + \"vehicles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec18468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating\n",
    "agents_df = format_demand(metro_trips)[0]\n",
    "alts_df = format_demand(metro_trips)[1]\n",
    "trips_df = format_demand(metro_trips)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a8f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
