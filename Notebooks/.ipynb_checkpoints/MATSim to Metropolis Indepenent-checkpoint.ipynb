{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f3f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyarrow\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import mpl_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from xopen import xopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f881f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share of the population that is simulated.\n",
    "POPULATION_SHARE = 0.10\n",
    "# Path to MATSim's network.\n",
    "NETWORK_PATH = (\n",
    "    \"/Users/andre/Desktop/Cergy/MATSim/matsim-berlin/input/v6.4/berlin-v6.4-network.xml.gz\"\n",
    ")\n",
    "# Path to MATSim's vehicles.\n",
    "VEHICLE_PATH = (\n",
    "    \"/Users/andre/Desktop/Cergy/MATSim/matsim-berlin/input/v6.4/berlin-v6.4-vehicleTypes.xml\"\n",
    ")\n",
    "# Path to MATSim's plans.\n",
    "PLAN_PATH = \"/Users/andre/Desktop/Cergy/MATSim/matsim-berlin/berlin-v6.4.output_plans.xml.gz\"\n",
    "\n",
    "# Path to the directory where the Metropolis input should be stored.\n",
    "MATSIM_PLANS = \"/Users/andre/Desktop/Cergy/Python_Scripts/runs/fixed_10pct/matsim/\"\n",
    "\n",
    "OUTPUT_DIR = \"/Users/andre/Desktop/Cergy/Python_Scripts/runs/fixed_10pct/input/\"\n",
    "\n",
    "# Parameters to use for the simulation.\n",
    "PARAMETERS ={\n",
    "    \"input_files\": {\n",
    "      \"agents\": \"/Users/andre/Desktop/Cergy/Python_Scripts/runs/fixed_10pct/input/agents.parquet\",\n",
    "      \"alternatives\": \"/Users/andre/Desktop/Cergy/Python_Scripts/runs/fixed_10pct/input/alts.parquet\",\n",
    "      \"trips\": \"/Users/andre/Desktop/Cergy/Python_Scripts/runs/fixed_10pct/input/trips.parquet\",\n",
    "      \"edges\": \"/Users/andre/Desktop/Cergy/Python_Scripts/runs/fixed_10pct/input/edges.parquet\",\n",
    "      \"vehicle_types\": \"/Users/andre/Desktop/Cergy/Python_Scripts/runs/fixed_10pct/input/vehicles.parquet\"\n",
    "    },\n",
    "    \"output_directory\": \"/Users/andre/Desktop/Cergy/Python_Scripts/runs/fixed_10pct/output/\",\n",
    "    \"period\": [0.0, 86400.0],\n",
    "    \"road_network\": {\n",
    "        \"recording_interval\": 950.0,\n",
    "        \"approximation_bound\": 1.0,\n",
    "        \"spillback\": True,\n",
    "        \"backward_wave_speed\": 15.0,\n",
    "        \"max_pending_duration\": 30.0,\n",
    "        \"constrain_inflow\": True,\n",
    "        \"algorithm_type\": \"Best\"\n",
    "    },\n",
    "    \"learning_model\": {\n",
    "      \"type\": \"Linear\"\n",
    "    },\n",
    "    \"init_iteration_counter\": 1,\n",
    "    \"max_iterations\": 1,\n",
    "    \"update_ratio\": 1.0,\n",
    "    \"random_seed\": 13081996,\n",
    "    \"nb_threads\": 8,\n",
    "    \"saving_format\": \"Parquet\",\n",
    "    \"only_compute_decisions\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd722575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_attributes(elem, my_dict):\n",
    "    for attrib in elem.attrib:\n",
    "        my_dict[attrib] = elem.attrib[attrib]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97d54a",
   "metadata": {},
   "source": [
    "# Offre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4860be2",
   "metadata": {},
   "source": [
    "## Lecture MATSim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e937346b",
   "metadata": {},
   "source": [
    "### Vehicules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83cd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_reader():\n",
    "    tree = ET.iterparse(xopen(VEHICLE_PATH, \"r\"), events=[\"start\", \"end\"])\n",
    "    vehicle_types = []\n",
    "    current_vehicle_type = {}\n",
    "    is_parsing_vehicle_type = False\n",
    "    for xml_event, elem in tree:\n",
    "        _, _, elem_tag = elem.tag.partition(\"}\")  # Removing xmlns tag from tag name\n",
    "        # VEHICLETYPES\n",
    "        if elem_tag == \"vehicleType\" and xml_event == \"start\":\n",
    "            parse_attributes(elem, current_vehicle_type)\n",
    "            is_parsing_vehicle_type = True\n",
    "        # ATTRIBUTES\n",
    "        elif elem_tag == \"attribute\" and xml_event == \"start\":\n",
    "            current_vehicle_type[elem.attrib[\"name\"]] = elem.text\n",
    "        # LENGTH / WIDTH\n",
    "        elif elem_tag in [\"length\", \"width\"] and xml_event == \"start\":\n",
    "            current_vehicle_type[elem_tag] = elem.attrib[\"meter\"]\n",
    "        # VEHICLETYPES\n",
    "        elif elem_tag == \"vehicleType\" and xml_event == \"end\":\n",
    "            vehicle_types.append(current_vehicle_type)\n",
    "            current_vehicle_type = {}\n",
    "            elem.clear()\n",
    "            is_parsing_vehicle_type = False\n",
    "        # EVERYTHING ELSE\n",
    "        elif is_parsing_vehicle_type and elem_tag not in [\"attribute\", \"length\", \"width\"]:\n",
    "            parse_attributes(elem, current_vehicle_type)\n",
    "    vehicle_types = pd.DataFrame.from_records(vehicle_types)\n",
    "    col_types = {\n",
    "        \"accessTimeInSecondsPerPerson\": float,\n",
    "        \"egressTimeInSecondsPerPerson\": float,\n",
    "        \"seats\": int,\n",
    "        \"standingRoomInPersons\": int,\n",
    "        \"length\": float,\n",
    "        \"width\": float,\n",
    "        \"pce\": float,\n",
    "        \"factor\": float,\n",
    "    }\n",
    "    for col, dtype in col_types.items():\n",
    "        if col in vehicle_types.columns:\n",
    "            try:\n",
    "                vehicle_types[col] = vehicle_types[col].astype(dtype)\n",
    "            except:\n",
    "                print(f\"dataframe types conversion failed for column {col}\")\n",
    "    return vehicle_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d082284",
   "metadata": {},
   "source": [
    "### Réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e2794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nodes():\n",
    "\n",
    "    node_data = []\n",
    "\n",
    "    for event, elem in ET.iterparse(xopen(NETWORK_PATH, \"r\"), events=[\"start\"]):\n",
    "        if elem.tag == \"node\":\n",
    "            try:\n",
    "                node_id = (elem.attrib[\"id\"])\n",
    "                x = float(elem.attrib[\"x\"])\n",
    "                y = float(elem.attrib[\"y\"])\n",
    "                node_data.append((node_id, x, y))\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar nodo: {e}\")\n",
    "                \n",
    "        if event == \"end\" and elem.tag == \"node\":\n",
    "            elem.clear()\n",
    "            \n",
    "    nodes_df = pd.DataFrame(node_data, columns=[\"node_id\", \"x\", \"y\"])\n",
    "    \n",
    "    # Limpiar solo los IDs que tienen \"cluster\"\n",
    "    nodes_df.loc[nodes_df[\"node_id\"].str.contains(\"cluster\"), \"node_id\"] = (\n",
    "        nodes_df.loc[nodes_df[\"node_id\"].str.contains(\"cluster\"), \"node_id\"]\n",
    "        .str.replace(\"cluster_\", \"\", regex=False)\n",
    "        .str.split(\"_\")\n",
    "        .str[0]\n",
    "    )\n",
    "    nodes_df[\"node_id\"] = nodes_df[\"node_id\"].astype(int)\n",
    "    \n",
    "    return nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70794a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_network():\n",
    "    tree = ET.iterparse(xopen(NETWORK_PATH, \"r\"), events=[\"start\", \"end\"])\n",
    "    links = []\n",
    "    \n",
    "    for xml_event, elem in tree:\n",
    "        \n",
    "        \n",
    "                \n",
    "        if elem.tag == \"link\" and xml_event == \"start\":\n",
    "            atts = elem.attrib\n",
    "            \n",
    "            # Remove '#' from link_id\n",
    "            atts[\"link_id\"] = atts[\"id\"].replace(\"#\", \"\")\n",
    "            atts[\"numeric_link_id\"] = int(atts[\"id\"].split(\"#\")[0])            \n",
    "            \n",
    "            atts[\"from_node\"] = atts.pop(\"from\")\n",
    "            atts[\"to_node\"] = atts.pop(\"to\")\n",
    "             \n",
    "            if \"cluster\" in atts[\"from_node\"]:\n",
    "                atts[\"from_node\"] = atts[\"from_node\"].replace(\"cluster_\", \"\").split(\"_\")[0]\n",
    "            if \"cluster\" in atts[\"to_node\"]:\n",
    "                atts[\"to_node\"] = atts[\"to_node\"].replace(\"cluster_\", \"\").split(\"_\")[0]\n",
    "            \n",
    "            \n",
    "            atts[\"length\"] = float(atts[\"length\"])\n",
    "            atts[\"freespeed\"] = float(atts[\"freespeed\"])\n",
    "            atts[\"capacity\"] = float(atts[\"capacity\"])\n",
    "            atts[\"permlanes\"] = float(atts[\"permlanes\"])\n",
    "            \n",
    "            if \"volume\" in atts:\n",
    "                atts[\"volume\"] = float(atts[\"volume\"])\n",
    "                \n",
    "            links.append(atts)\n",
    "            \n",
    "        # clear the element when we're done, to keep memory usage low\n",
    "        if elem.tag in [\"node\", \"link\"] and xml_event == \"end\":\n",
    "            elem.clear()\n",
    "            \n",
    "    links = pd.DataFrame.from_records(links)\n",
    "    links = links.loc[links[\"modes\"].str.contains(\"car\")].copy()\n",
    "    links[\"link_id\"] = links[\"link_id\"].astype(int)\n",
    "    links[\"from_node\"] = links[\"from_node\"].astype(int)\n",
    "    links[\"to_node\"] = links[\"to_node\"].astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    node_pair_counts = links[[\"from_node\", \"to_node\"]].value_counts()\n",
    "    if node_pair_counts.max() > 2:\n",
    "        print(\"More than two parallel edges\")\n",
    "        \n",
    "    parallel_idx = node_pair_counts.loc[node_pair_counts > 1].index\n",
    "    if len(parallel_idx):\n",
    "        print(\"Found {} parallel edges\".format(len(parallel_idx)))\n",
    "        next_node_id = max(links[\"from_node\"].max(), links[\"to_node\"].max()) + 1\n",
    "        next_link_id = links[\"link_id\"].max() + 1\n",
    "        new_rows = list()\n",
    "        for (source, target) in parallel_idx:\n",
    "            mask = (links[\"from_node\"] == source) & (links[\"to_node\"] == target)\n",
    "            idx = mask[mask].index\n",
    "            row = links.loc[idx[1]].copy()\n",
    "            row[\"length\"] = 0.0\n",
    "            row[\"from_node\"] = next_node_id\n",
    "            row[\"link_id\"] = next_link_id\n",
    "            new_rows.append(row)\n",
    "            links.loc[idx[1], \"to_node\"] = next_node_id\n",
    "            next_link_id += 1\n",
    "            next_node_id += 1\n",
    "        links = pd.concat((links, pd.DataFrame(new_rows)))\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac30910",
   "metadata": {},
   "source": [
    "Régler question de 3 arcs (//)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ebe40",
   "metadata": {},
   "source": [
    "# Ecriture d'inputs METROPOLIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21cefa6",
   "metadata": {},
   "source": [
    "## Supply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb654bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edges_df(links):\n",
    "    edge_list = []\n",
    "\n",
    "    for i, (_, row) in enumerate(links.iterrows()):\n",
    "        edge = {\n",
    "            \"edge_id\": i+1,\n",
    "            \"MATSim_id\": row[\"id\"],\n",
    "            \"source\": int(row[\"from_node\"]),\n",
    "            \"target\": int(row[\"to_node\"]),\n",
    "            \"speed\": float(row[\"freespeed\"]),\n",
    "            \"length\": float(row[\"length\"]),\n",
    "            \"lanes\": float(row[\"permlanes\"]),\n",
    "            \"speed_density.type\": \"FreeFlow\",\n",
    "            \"speed_density.capacity\": None,\n",
    "            \"speed_density.min_density\": None,\n",
    "            \"speed_density.jam_density\": None,\n",
    "            \"speed_density.jam_speed\": None,\n",
    "            \"speed_density.beta\": None,\n",
    "            \"bottleneck_flow\": float(row[\"capacity\"])*0.9/ (row['permlanes']*3600.0),  # capacity per lane in vehicles per hour\n",
    "            \"constant_travel_time\": math.ceil(float(row[\"length\"]) / float(row[\"freespeed\"])) - float(row[\"length\"]) / float(row[\"freespeed\"]),\n",
    "            \"overtaking\": True\n",
    "        }\n",
    "        edge_list.append(edge)\n",
    "\n",
    "    edges = pd.DataFrame(edge_list)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce01ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vehicles_df(vehicle_types):\n",
    "    vehicle_list = []\n",
    "\n",
    "    for idx, row in vehicle_types.iterrows():\n",
    "        if row[\"id\"] == \"ride\":\n",
    "            vehicle = {\n",
    "                \"vehicle_id\": idx,\n",
    "                \"vehicle_type\": row[\"id\"],\n",
    "                \"headway\": float(row[\"length\"]),\n",
    "                \"pce\": 0.0,\n",
    "                \"speed_function.type\": \"Base\",\n",
    "                \"speed_function.upper_bound\": None,\n",
    "                \"speed_function.coef\": None,\n",
    "            }\n",
    "        else:\n",
    "            vehicle = {\n",
    "                \"vehicle_id\": idx,\n",
    "                \"vehicle_type\": row[\"id\"],\n",
    "                \"headway\": float(row[\"length\"]),\n",
    "                \"pce\": float(row[\"pce\"]) / POPULATION_SHARE,\n",
    "                \"speed_function.type\": \"Base\",\n",
    "                \"speed_function.upper_bound\": None,\n",
    "                \"speed_function.coef\": None,\n",
    "            }\n",
    "        vehicle_list.append(vehicle)\n",
    "\n",
    "    vehicles = pd.DataFrame(vehicle_list)\n",
    "    return vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfd63b7",
   "metadata": {},
   "source": [
    "## Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb1eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_reader_dataframe(selected_plans_only=True):\n",
    "    \n",
    "    tree = ET.iterparse(xopen(PLAN_PATH), events=[\"start\", \"end\"])\n",
    "    persons = []\n",
    "    plans = []\n",
    "    activities = []\n",
    "    legs = []\n",
    "    routes = []\n",
    "    current_person = {}\n",
    "    current_plan = {}\n",
    "    current_activity = {}\n",
    "    current_leg = {}\n",
    "    current_route = {}\n",
    "    current_person = {}\n",
    "    current_plan = {}\n",
    "    current_activity = {}\n",
    "    current_leg = {}\n",
    "    current_route = {}\n",
    "\n",
    "    is_parsing_person = False\n",
    "    is_parsing_activity = False\n",
    "    is_parsing_leg = False\n",
    "    is_selected_plan = True\n",
    "\n",
    "    current_person_id = None\n",
    "    current_plan_id = 0\n",
    "    current_activity_id = 0\n",
    "    current_leg_id = 0\n",
    "    current_route_id = 0\n",
    "\n",
    "    for xml_event, elem in tree:\n",
    "        if xml_event == \"start\":\n",
    "            \n",
    "            if elem.tag == \"person\":\n",
    "                current_person[\"id\"] = elem.attrib[\"id\"]\n",
    "                current_person_id = elem.attrib[\"id\"]\n",
    "                is_parsing_person = True\n",
    "            \n",
    "            # PLAN\n",
    "            if elem.tag == \"plan\":\n",
    "                is_selected_plan = not selected_plans_only or elem.attrib.get(\"selected\", \"no\") == \"yes\"\n",
    "                if not is_selected_plan:\n",
    "                    continue\n",
    "                current_plan[\"id\"] = current_plan_id\n",
    "                current_plan[\"person_id\"] = current_person_id\n",
    "                current_plan_id += 1\n",
    "                parse_attributes(elem, current_plan)\n",
    "\n",
    "            # ACTIVITY\n",
    "            elif elem.tag == \"activity\" and is_selected_plan:\n",
    "                is_parsing_activity = True\n",
    "                current_activity_id += 1\n",
    "                current_activity[\"id\"] = current_activity_id\n",
    "                current_activity[\"plan_id\"] = current_plan_id-1\n",
    "                parse_attributes(elem, current_activity)\n",
    "\n",
    "            # LEG\n",
    "            elif elem.tag == \"leg\" and is_selected_plan:\n",
    "                is_parsing_leg = True\n",
    "                current_leg_id += 1\n",
    "                current_leg[\"id\"] = current_leg_id\n",
    "                current_leg[\"plan_id\"] = current_plan_id-1\n",
    "                parse_attributes(elem, current_leg)\n",
    "\n",
    "            # ROUTE\n",
    "            elif elem.tag == \"route\" and is_selected_plan:\n",
    "                current_route_id += 1\n",
    "                current_route[\"id\"] = current_route_id\n",
    "                current_route[\"leg_id\"] = current_leg_id\n",
    "                current_route[\"value\"] = elem.text\n",
    "                parse_attributes(elem, current_route)\n",
    "        \n",
    "        elif xml_event == \"end\":\n",
    "            \n",
    "        # PERSON\n",
    "            if elem.tag == \"person\":\n",
    "                persons.append(current_person)\n",
    "                current_person = {}\n",
    "                is_parsing_person = False\n",
    "\n",
    "        \n",
    "        # PLAN \n",
    "            elif elem.tag == \"plan\" and is_selected_plan:\n",
    "                plans.append(current_plan)\n",
    "                current_plan = {}\n",
    "                \n",
    "         # ACTIVITY\n",
    "            elif elem.tag == \"activity\" and is_parsing_activity and is_selected_plan:\n",
    "                activities.append(current_activity)\n",
    "                current_activity = {}\n",
    "                is_parsing_activity = False\n",
    "                \n",
    "        # LEG\n",
    "            elif elem.tag == \"leg\" and is_parsing_leg and is_selected_plan:\n",
    "                legs.append(current_leg)\n",
    "                current_leg = {}\n",
    "                is_parsing_leg = False\n",
    "                \n",
    "        # ROUTE\n",
    "            elif elem.tag == \"route\" and is_selected_plan:\n",
    "                routes.append(current_route)\n",
    "                current_route = {}\n",
    "                \n",
    "            elif elem.tag == \"attribute\":\n",
    "                attribs = elem.attrib\n",
    "                if is_parsing_activity and is_selected_plan:\n",
    "                    current_activity[attribs[\"name\"]] = elem.text\n",
    "                elif is_parsing_leg and is_selected_plan:\n",
    "                    current_leg[attribs[\"name\"]] = elem.text\n",
    "                elif is_parsing_person:\n",
    "                    current_person[attribs[\"name\"]] = elem.text\n",
    "            elem.clear()\n",
    "\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    return (\n",
    "        pd.DataFrame(persons),\n",
    "        pd.DataFrame(plans),\n",
    "        pd.DataFrame(activities),\n",
    "        pd.DataFrame(legs),\n",
    "        pd.DataFrame(routes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab23e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trips(plans, legs, routes, edges, vehicles):\n",
    "    \n",
    "    # Only selected plans\n",
    "    plans = plans.loc[plans[\"selected\"] == \"yes\"].copy()\n",
    "    \n",
    "    # Filter by legs corresponding to selected plans\n",
    "    legs = legs.loc[legs[\"plan_id\"].isin(plans[\"id\"])].copy()\n",
    "    legs[\"dep_time\"] = pd.to_timedelta(legs[\"dep_time\"]).dt.total_seconds()\n",
    "    legs[\"trav_time\"] = pd.to_timedelta(routes[\"trav_time\"]).dt.total_seconds()\n",
    "    \n",
    "    # \"Add\" travel time to the legs dataframe\n",
    "    routes[\"trav_time\"] = pd.to_timedelta(routes[\"trav_time\"]).dt.total_seconds()\n",
    "    legs = legs.merge(\n",
    "        routes[[\"leg_id\", \"trav_time\"]],\n",
    "        left_on=\"id\",\n",
    "        right_on=\"leg_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    legs.drop(columns=[\"leg_id\"], inplace=True)\n",
    "    legs.rename(columns={\"trav_time_y\": \"trav_time\"}, inplace=True)\n",
    "    legs.drop(columns=[\"trav_time_x\"], inplace=True)\n",
    "    \n",
    "    # Eliminate pt and walking segments\n",
    "    legs = legs[(legs['mode'] == 'car') & (legs[\"routingMode\"]==\"car\")]\n",
    "    \n",
    "    \n",
    "    # Create Metropolis routes by matching links to edges in a dictionary\n",
    "    matsim_to_metro_routes = dict(zip(edges[\"MATSim_id\"].astype(str), edges[\"edge_id\"]))\n",
    "\n",
    "    routes[\"split_links\"] = routes.apply(\n",
    "        lambda row: None if row[\"type\"] in [\"generic\", \"default_pt\"] or pd.isnull(row[\"value\"])\n",
    "        else row[\"value\"].strip().split(),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    routes[\"class.route\"] = routes[\"split_links\"].apply(\n",
    "        lambda link_list: None if link_list is None\n",
    "        else [matsim_to_metro_routes.get(link) for link in link_list[1:]]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Transform routes, legs, vehicles and edges to polars\n",
    "    edges = pl.from_pandas(edges)\n",
    "    vehicles = pl.from_pandas(vehicles)\n",
    "    \n",
    "    routes = (\n",
    "        pl.from_pandas(routes)\n",
    "        .filter(pl.col(\"leg_id\").is_in(legs[\"id\"]))\n",
    "        .with_columns(pl.col(\"value\").str.split(\" \"))\n",
    "    )\n",
    "    legs = (\n",
    "        pl.from_pandas(legs)\n",
    "        .with_columns(\n",
    "            pl.col(\"dep_time\").shift(-1).over(\"plan_id\").alias(\"next_dep_time\"),\n",
    "            (pl.col(\"dep_time\") + pl.col(\"trav_time\")).alias(\"arr_time\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            (pl.col(\"next_dep_time\") - pl.col(\"arr_time\")).fill_null(0.0).alias(\"stopping_time\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Join legs and routes\n",
    "    legs = legs.join(routes, left_on=\"id\", right_on=\"leg_id\", how=\"left\") # to get \"start and end links\"\n",
    "\n",
    "    # Define trips as startig from the start_link target node and end at the \n",
    "    # Join with edges for start_link's from and to nodes\n",
    "    legs = legs.join(edges.select([\n",
    "            pl.col(\"MATSim_id\").alias(\"start_link\"),\n",
    "            pl.col(\"target\").alias(\"end_source\")\n",
    "        ]),\n",
    "        on=\"start_link\",\n",
    "        how=\"left\")\n",
    "    \n",
    "    # Join for end_link\n",
    "    legs = legs.join(edges.select([\n",
    "            pl.col(\"MATSim_id\").alias(\"end_link\"),\n",
    "            pl.col(\"target\").alias(\"end_target\")\n",
    "        ]),\n",
    "        on=\"end_link\",\n",
    "        how=\"left\")\n",
    "    \n",
    "    # Loop per agent\n",
    "    all_metro_legs = []\n",
    "    \n",
    "    for plan_id in plans[\"id\"]:\n",
    "        if not plan_id in legs[\"plan_id\"]:\n",
    "            # Missing plan.\n",
    "            continue\n",
    "        \n",
    "        metro_legs = legs.filter(pl.col(\"plan_id\") == plan_id)\n",
    "        metro_legs = metro_legs.with_columns(pl.col(\"id\").cast(pl.Int64))\n",
    "        metro_legs = metro_legs.drop(['id_right', 'trav_time_right', 'distance'])\n",
    "                \n",
    "\n",
    "        # class.destination\n",
    "        metro_legs = metro_legs.join(\n",
    "            edges.select([pl.col(\"MATSim_id\").alias(\"end_link\"), pl.col(\"edge_id\").alias(\"class.destination\")]),\n",
    "            on=\"end_link\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # class.vehicle\n",
    "        metro_legs = metro_legs.join(\n",
    "            vehicles.select([\n",
    "                pl.col(\"vehicle_type\").alias(\"mode\"),\n",
    "                pl.col(\"vehicle_id\").alias(\"class.vehicle\")]),\n",
    "            on=\"mode\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # Condition for class.type = \"Virtual\"\n",
    "        virtual_condition = pl.col(\"type\").is_in([\"generic\", \"default_pt\"]) | pl.col(\"value\").is_null()\n",
    "\n",
    "        metro_legs = metro_legs.with_columns([\n",
    "            \n",
    "            \n",
    "            # class.type\n",
    "            pl.when(virtual_condition)\n",
    "            .then(pl.lit(\"Virtual\"))\n",
    "            .otherwise(pl.lit(\"Road\"))\n",
    "            .alias(\"class.type\"),\n",
    "            \n",
    "            # class.origin\n",
    "            pl.col(\"end_source\").alias(\"class.origin\"),\n",
    "            \n",
    "            # class.destination\n",
    "            pl.col(\"end_target\").alias(\"class.destination\"),\n",
    "            \n",
    "            \n",
    "            # class.travel_time\n",
    "            pl.when(virtual_condition)\n",
    "              .then(pl.col(\"trav_time\"))\n",
    "            .otherwise(None)\n",
    "            .alias(\"class.travel_time\"),\n",
    "\n",
    "\n",
    "            \n",
    "            # stopping_time\n",
    "            pl.when(pl.col(\"stopping_time\") > 0)\n",
    "              .then(pl.col(\"stopping_time\"))\n",
    "              .otherwise(None)\n",
    "              .alias(\"stopping_time\")\n",
    "        ])\n",
    "        \n",
    "        metro_legs = metro_legs.with_columns([\n",
    "            pl.lit(1).alias(\"alt_id\"),\n",
    "            pl.lit(\"Constant\").alias(\"dt_choice.type\"),\n",
    "            pl.col(\"dep_time\").alias(\"dt_choice.departure_time\")])\n",
    "        \n",
    "        metro_legs = metro_legs.drop(\"dep_time\", \"value\", \"routingMode\", \"trav_time\", \"vehicleRefId\",\n",
    "                                     \"start_link\" ,\"end_link\", \"end_source\", \"end_target\")\n",
    "                \n",
    "        all_metro_legs.append(metro_legs)\n",
    "        \n",
    "    all_metro_legs = pl.concat(all_metro_legs, how=\"vertical\")\n",
    "    return all_metro_legs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b470e",
   "metadata": {},
   "source": [
    "# Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7da5a6",
   "metadata": {},
   "source": [
    "## Offre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b91dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_supply(edges, vehicles):\n",
    "    edges = (pl.from_pandas(edges)).drop([\"MATSim_id\"])\n",
    "    vehicles = (pl.from_pandas(vehicles)).drop([\"vehicle_type\"])\n",
    "    vehicles = vehicles.filter(pl.col(\"vehicle_id\") < 3)\n",
    "    \n",
    "    return [edges, vehicles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb97542",
   "metadata": {},
   "source": [
    "## Demande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64dc4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_demand(trips):\n",
    "    # format trips\n",
    "    trips = trips.rename({\"id\": \"trip_id\",\"plan_id\": \"agent_id\"}).select([\n",
    "        \"agent_id\", \"alt_id\", \"trip_id\", \n",
    "        \"class.type\", \"class.origin\", \"class.destination\", \"class.vehicle\", \"class.route\", \"class.travel_time\", \"stopping_time\", \n",
    "        \"dt_choice.type\", \"dt_choice.departure_time\"\n",
    "    ])\n",
    "\n",
    "    # Format trips (filter out bad Road legs first)\n",
    "    trips = trips.filter(~((pl.col(\"class.type\") == \"Road\") &\n",
    "                           (pl.col(\"class.origin\").is_null() | pl.col(\"class.destination\").is_null())\n",
    "        ))\n",
    "            \n",
    "    # format agents\n",
    "    agents = trips.select(\"agent_id\").unique().with_columns([\n",
    "        pl.lit(\"Deterministic\").alias(\"alt_choice.type\"),\n",
    "        pl.lit(0.0).alias(\"alt_choice.u\"),\n",
    "        pl.lit(None).alias(\"alt_choice.mu\")\n",
    "    ]).sort(\"agent_id\")\n",
    "\n",
    "    # format alts\n",
    "    alts = (\n",
    "        trips.sort(\"dt_choice.departure_time\")\n",
    "        .unique(subset=[\"agent_id\"], keep=\"first\")\n",
    "        .with_columns([\n",
    "            pl.lit(1).alias(\"alt_id\"),\n",
    "            pl.col(\"dt_choice.departure_time\")\n",
    "        ])\n",
    "        .select([\n",
    "            \"agent_id\",\n",
    "            \"alt_id\",\n",
    "            pl.lit(None).alias(\"origin_delay\"),\n",
    "            pl.col(\"dt_choice.type\"),\n",
    "            \"dt_choice.departure_time\",\n",
    "\n",
    "            pl.lit(None).alias(\"dt_choice.interval\"),\n",
    "            pl.lit(None).alias(\"dt_choice.model.type\"),\n",
    "            pl.lit(0.0).alias(\"dt_choice.model.u\"),\n",
    "            pl.lit(0.0).alias(\"dt_choice.model.mu\"),\n",
    "            pl.lit(None).alias(\"dt_choice.offset\"),\n",
    "\n",
    "            pl.lit(0.0).alias(\"constant_utility\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.one\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.two\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.three\"),\n",
    "            pl.lit(None).alias(\"total_travel_utility.four\"),\n",
    "\n",
    "            pl.lit(None).alias(\"origin_utility.type\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.tstar\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.beta\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.gamma\"),\n",
    "            pl.lit(0.0).alias(\"origin_utility.delta\"),\n",
    "\n",
    "            pl.lit(None).alias(\"destination_utility.type\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.tstar\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.beta\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.gamma\"),\n",
    "            pl.lit(0.0).alias(\"destination_utility.delta\"),\n",
    "\n",
    "            pl.lit(True).alias(\"pre_compute_route\")\n",
    "        ])\n",
    "    )\n",
    "    alts = alts.sort(\"agent_id\")\n",
    "    \n",
    "    trips = trips.drop([\"dt_choice.type\", \"dt_choice.departure_time\"])\n",
    "\n",
    "    \n",
    "    return agents, alts, trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf70d8",
   "metadata": {},
   "source": [
    "# Run code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02dfbe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MATSim network\n",
      "More than two parallel edges\n",
      "Found 1842 parallel edges\n",
      "Reading MATSim vehicles\n",
      "dataframe types conversion failed for column seats\n",
      "dataframe types conversion failed for column standingRoomInPersons\n",
      "Generating Metropolis network\n",
      "Generating Metropolis vehicles\n",
      "Reading MATSim agents\n"
     ]
    }
   ],
   "source": [
    "# Extract MATSim supply\n",
    "print(\"Reading MATSim network\")\n",
    "links = read_network()\n",
    "\n",
    "print(\"Reading MATSim vehicles\")\n",
    "vehicle = vehicle_reader()\n",
    "\n",
    "# Generate METRO supply\n",
    "print(\"Generating Metropolis network\")\n",
    "edges = make_edges_df(links)\n",
    "print(\"Generating Metropolis vehicles\")\n",
    "vehicles = make_vehicles_df(vehicle)\n",
    "\n",
    "# Formating\n",
    "edges_df = format_supply(edges, vehicles)[0]\n",
    "vehicles_df = format_supply(edges, vehicles)[1]\n",
    "\n",
    "# Extract MATSim Demand\n",
    "print(\"Reading MATSim agents\")\n",
    "plan_df = plan_reader_dataframe()\n",
    "persons=plan_df[0]\n",
    "plans = plan_df[1]\n",
    "activities=plan_df[2] \n",
    "legs = plan_df[3]\n",
    "routes = plan_df[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1339e2eb",
   "metadata": {},
   "source": [
    "## Write MATSim files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATSim files\n",
    "# Writing files\n",
    "print(\"Writing files to\", MATSIM_PLANS)\n",
    "persons.to_parquet(MATSIM_PLANS + \"MATSim_persons.parquet\")\n",
    "plans.to_parquet(MATSIM_PLANS + \"MATSim_plans.parquet\")\n",
    "activities.to_parquet(MATSIM_PLANS + \"MATSim_activities.parquet\")\n",
    "#links.to_parquet(MATSIM_PLANS + \"MATSim_links.parquet\")\n",
    "legs.to_parquet(MATSIM_PLANS + \"MATSim_legs.parquet\")\n",
    "routes.to_parquet(MATSIM_PLANS + \"MATSim_routes.parquet\")\n",
    "\n",
    "print(\"MATSim files have been successfully written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe323d",
   "metadata": {},
   "source": [
    "# Separating all trips as a single agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate METRO Demand\n",
    "print(\"Generating Metropolis agents\")\n",
    "trips = generate_trips(plans, legs, routes, edges, vehicles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dee6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_trips = trips.filter(\n",
    "    pl.col(\"class.type\") == \"Road\", # Eliminate Virtual trips\n",
    "    pl.col(\"dt_choice.departure_time\") <= 108000).with_columns(\n",
    "    \n",
    "    pl.lit(1).alias(\"alt_id\"),\n",
    "    pl.concat_str([\n",
    "        pl.col(\"plan_id\").cast(pl.Utf8),\n",
    "        pl.col(\"alt_id\").cast(pl.Utf8).str.zfill(2),\n",
    "        pl.col(\"id\").cast(pl.Utf8)\n",
    "    ]).cast(pl.Int64).alias(\"plan_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c01f1",
   "metadata": {},
   "source": [
    "## Write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4b932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Formating\n",
    "ind_agents_df = format_demand(ind_trips)[0]\n",
    "ind_alts_df = format_demand(ind_trips)[1]\n",
    "ind_trips_df = format_demand(ind_trips)[2]\n",
    "\n",
    "# Parameters\n",
    "print(\"Writing Metropolis parameters\")\n",
    "with open(os.path.join(OUTPUT_DIR, \"parameters.json\"), \"w\") as f:\n",
    "    f.write(json.dumps(PARAMETERS))\n",
    "# Writing files\n",
    "print(\"Writing files to\", OUTPUT_DIR)\n",
    "edges_df.write_parquet(OUTPUT_DIR + \"edges.parquet\")\n",
    "vehicles_df.write_parquet(OUTPUT_DIR + \"vehicles.parquet\")\n",
    "ind_agents_df.write_parquet(OUTPUT_DIR + \"agents.parquet\")\n",
    "ind_alts_df.write_parquet(OUTPUT_DIR + \"alts.parquet\")\n",
    "ind_trips_df.write_parquet(OUTPUT_DIR + \"trips.parquet\")\n",
    "print(\"Input files have been successfully written\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
